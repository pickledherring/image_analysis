{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import statistics as st\n",
    "import random\n",
    "import copy\n",
    "from numpy import arange, ravel, array\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise addition functions: \n",
    "* Salt and pepper noise of user-specified strength \n",
    "* Gaussian noise of user-specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salt_n_pepper(img, prob):\n",
    "    # prob should be int [0 - 1], recommend <.1\n",
    "    new_img = []\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            if random.random() <= prob:\n",
    "                if random.choice([\"black\", \"white\"]) == \"black\":\n",
    "                    new_img[i].append(0)\n",
    "                else:\n",
    "                    new_img[i].append(255)\n",
    "            else:\n",
    "                new_img[i].append(img[i][j])\n",
    "    return new_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(img, mu=0, sigma=1):\n",
    "    new_img = []\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            new_val = img[i][j] + random.gauss(mu, sigma)\n",
    "            if new_val < 0:\n",
    "                new_img[i].append(0)\n",
    "            elif new_val > 255:\n",
    "                new_img[i].append(1)\n",
    "            else:\n",
    "                new_img[i].append(new_val)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting color images to selected single color spectrum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    new_img = []\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            # CIE recommended constants\n",
    "            grey = .2126 * img[i][j][0] + .7152 * img[i][j][1]+ .0722 * img[i][j][2]\n",
    "            new_img[i].append(grey)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open_in_gray is the only function to open an image as all other functions are for grayscale images. run open_in gray on a file, then a function or functions on the returned image, then to_image on that return to get a viewable image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_in_gray(file):\n",
    "    img = Image.open(file)\n",
    "    width, height = img.size\n",
    "    pix = img.getdata()\n",
    "    pix_list = []\n",
    "    for y in range(height):\n",
    "        row = []\n",
    "        for x in range(width):\n",
    "            value = pix[y * width + x]\n",
    "            row.append(value)\n",
    "        pix_list.append(row)\n",
    "\n",
    "    # all functions are on grayscale, so this step is required\n",
    "    pix_list = grayscale(pix_list)\n",
    "    return pix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_image(pix_list, save_loc=None):\n",
    "    size = [len(pix_list[0]), len(pix_list)]\n",
    "    flat_list = []\n",
    "    for row in pix_list:\n",
    "        for i in range(len(row)):\n",
    "            value = row[i]\n",
    "            flat_list.append(value)\n",
    "    output = Image.new(\"L\", size)\n",
    "    output.putdata(flat_list)\n",
    "    \n",
    "    if save_loc:\n",
    "        output.save(f\"{save_loc}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram calculation for each individual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(img, bins=255):\n",
    "    bin_divs = []\n",
    "    counts = []\n",
    "    for i in range(1, bins + 1):\n",
    "        bin_divs.append(i * 255/bins)\n",
    "        counts.append(0)\n",
    "\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[i])):\n",
    "            # better as a binary search\n",
    "            for k in range(bins):\n",
    "                if img[i][j] <= bin_divs[k]:\n",
    "                    counts[k] += 1\n",
    "                    break\n",
    "    \n",
    "    return bin_divs, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(bin_divs, counts, title=None):\n",
    "    half_width = bin_divs[0]/2\n",
    "    plt.bar([x - half_width for x in bin_divs], counts, width = half_width*2)\n",
    "    plt.xlabel(\"intensity\")\n",
    "    plt.ylabel(\"count\")\n",
    "    if title:\n",
    "            titles = {\"cyl\": \"columnar epithelial\",\n",
    "                    \"para\": \"parabasal squamous epithelial\",\n",
    "                    \"inter\": \"intermediate squamous epithelial\",\n",
    "                    \"super\": \"superficial squamous epithelial\",\n",
    "                    \"let\": \"mild nonkeratinizing dysplastic\",\n",
    "                    \"mod\": \"moderate nonkeratinizing dysplastic\",\n",
    "                    \"svar\": \"severe nonkeratinizing dysplastic\"}\n",
    "            plt.title(titles[title])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaged histograms of pixel values for each class of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hist_avg_class can be run independently of open_in_gray as it runs it internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_avg_class(folder, abbr, bins=255, plot=False):\n",
    "    # abbr can be:\n",
    "    # \"cyl\": columnar epithelial?\n",
    "    # \"para\": parabasal squamous epithelial\n",
    "    # \"inter\": intermediate squamous epithelial\n",
    "    # \"super\": superficial squamous epithelial\n",
    "    # \"let\": mild nonkeratinizing dysplastic?\n",
    "    # \"mod\": moderate nonkeratinizing dysplastic\n",
    "    # \"svar\": severe nonkeratinizing dysplastic?\n",
    "    files = glob.glob(f\"{folder}/{abbr}*\")\n",
    "\n",
    "    bin_divs = [i * 255/bins for i in range(1, bins + 1)]\n",
    "    counts = [0 for _ in range(bins)]\n",
    "    # open and grayscale each file\n",
    "    for file in files:\n",
    "        pix_list = open_in_gray(file)\n",
    "        # get and add counts\n",
    "        _, ind_counts = hist(pix_list, bins = bins)\n",
    "        counts = [a + b for a, b in zip(counts, ind_counts)]\n",
    "\n",
    "    # average counts\n",
    "    counts = [x / len(files) for x in counts]\n",
    "\n",
    "    return bin_divs, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram equalization for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_eq(img):\n",
    "    new_img = []\n",
    "    # get cdf\n",
    "    num_pix = len(img) * len(img[0])\n",
    "    _, counts = hist(img)\n",
    "    cdf = []\n",
    "    sum_int = 0\n",
    "    for i in range(len(counts)):\n",
    "        sum_int += counts[i]\n",
    "        cdf.append(math.floor(255 * sum_int / num_pix))\n",
    "    # apply cdf\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            new_img[i].append(cdf[int(img[i][j])])\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected image quantization technique for user-specified levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizer(img, num_levels):\n",
    "    new_img = []\n",
    "    bins = [i * 255/num_levels for i in range(1, num_levels + 1)]\n",
    "    dQ = 255 / num_levels\n",
    "    msqe = 0\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            for k in range(num_levels):\n",
    "                if img[i][j] <= bins[k]:\n",
    "                    new_img[i].append((k + .5) * dQ)\n",
    "                    msqe += (img[i][j] - new_img[i][j])**2\n",
    "                    break\n",
    "    msqe /= len(img) * len(img[0])\n",
    "\n",
    "    return new_img, msqe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bgnd_white_arrayify(img):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    # evaluate img, if mostly black, flip every pixel\n",
    "    # I assume the background will occupy most of the image\n",
    "    sum_white = sum([sum(img[i]) for i in range(len(img))])\n",
    "    if sum_white / 255 < length * width / 2:\n",
    "        less = ravel(img) - 255\n",
    "        inverted = abs(less)\n",
    "        inverted = inverted.reshape((length, width))\n",
    "    else:\n",
    "        inverted = array(img)\n",
    "    return inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img, amount):\n",
    "    # amount is width in pixels to crop from all edges\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    new_img = []\n",
    "    for i in range(length - 2 * amount):\n",
    "        new_img.append([])\n",
    "        for j in range(width - 2 * amount):\n",
    "            value = img[amount+i][amount+j]\n",
    "            new_img[i].append(value)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(img, amount):\n",
    "    # amount is width in pixels to pad on all edges\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    new_img = []\n",
    "    for i in range(length + 2 * amount):\n",
    "        new_img.append([])\n",
    "        for j in range(width + 2 * amount):\n",
    "            if i >= length + amount or j >= width + amount\\\n",
    "                or i < amount or j < amount:\n",
    "                value = 255\n",
    "            else:\n",
    "                value = img[i-amount][j-amount]\n",
    "            new_img[i].append(value)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_bounds(img, length, width, mask_size):\n",
    "    # works well when there is no border\n",
    "    new_img = []\n",
    "    for i in range(mask_size):\n",
    "        new_img.append([])\n",
    "        # top left corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i].append(img[length-mask_size+i][width-mask_size+j])\n",
    "        # top center\n",
    "        for j in range(width):\n",
    "            new_img[i].append(img[length-mask_size+i][j])\n",
    "        # top right corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i].append(img[length-mask_size+i][j])\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        # middle left\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+mask_size].append(img[i][width-mask_size+j])\n",
    "        # middle center\n",
    "        for j in range(width):\n",
    "            new_img[i+mask_size].append(img[i][j])\n",
    "        # middle right\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+mask_size].append(img[i][j])\n",
    "    for i in range(mask_size):\n",
    "        new_img.append([])\n",
    "        # bottom left corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+length+mask_size].append(img[i][width-mask_size+j])\n",
    "        # bottom center\n",
    "        for j in range(width):\n",
    "            new_img[i+length+mask_size].append(img[i][j])\n",
    "        # bottom right corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+length+mask_size].append(img[i][j])\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering operations: \n",
    "*Linear filter with user-specified mask size and pixel weights\n",
    "*Median filter with user-specified mask size and pixel weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_3x3 = [[1, 2, 1], [2, 4, 2], [1, 2, 1]]\n",
    "gauss_5x5 = [[1, 4, 7, 4, 1], [4, 16, 26, 16, 4], [7, 26, 41, 26, 7],\n",
    "            [4, 16, 26, 16, 4], [1, 4, 7, 4, 1]]\n",
    "dilate_erode_weights = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_linear_filter(img, weights=gauss_5x5, sum_weights=0):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    ext_img = ext_bounds(img, length, width, mask_radius)\n",
    "\n",
    "    # sum_weights can be changed from 0 for an edge detector or other\n",
    "    # filter where the sum would equal 0 and cause zero division error.\n",
    "    # Otherwise, the function will figure it out, below.\n",
    "    if sum_weights == 0:\n",
    "        for i in range(len(weights)):\n",
    "            sum_weights += sum(weights[i])\n",
    "        \n",
    "        if sum_weights == 0:\n",
    "            print(\"please supply a non-zero sum_weights for this filter,\\\n",
    "            maybe the sum of their absolute values.\")\n",
    "    \n",
    "    # apply filter\n",
    "    new_img = []\n",
    "    for i in range(mask_radius, length + mask_radius):\n",
    "        new_img.append([])\n",
    "        for j in range(mask_radius, width + mask_radius):\n",
    "            summed = 0\n",
    "            for k in range(len(weights)):\n",
    "                for m in range(len(weights[k])):\n",
    "                    summed += ext_img[i-mask_radius+k][j-mask_radius+m] *\\\n",
    "                    weights[k][m]\n",
    "            new_img[i-mask_radius].append(summed / sum_weights)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_linear_filter(img, weights=gauss_5x5):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    ext_img = ext_bounds(img, length, width, mask_radius)\n",
    "\n",
    "    # apply filter\n",
    "    new_img = []\n",
    "    for i in range(mask_radius, length + mask_radius):\n",
    "        new_img.append([])\n",
    "        for j in range(mask_radius, width + mask_radius):\n",
    "            products = []\n",
    "            for k in range(len(weights)):\n",
    "                for m in range(len(weights[k])):\n",
    "                    for _ in range(weights[k][m]):\n",
    "                        products.append(ext_img[i-mask_radius+k][j-mask_radius+m])\n",
    "            new_img[i-mask_radius].append(st.median(products))\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(folder, funcs, abbr=None, save_loc=None, verbose=False):\n",
    "    # funcs should be a tuple or list like:\n",
    "    # [[func1, {param1:arg1, param2:arg2}], [func2, {param1:arg1}]]\n",
    "    # where paramaters are anything besides \"img\" or \"folder\"\n",
    "    \n",
    "    # abbr can be:\n",
    "    # \"cyl\": columnar epithelial?\n",
    "    # \"para\": parabasal squamous epithelial\n",
    "    # \"inter\": intermediate squamous epithelial\n",
    "    # \"super\": superficial squamous epithelial\n",
    "    # \"let\": mild nonkeratinizing dysplastic?\n",
    "    # \"mod\": moderate nonkeratinizing dysplastic\n",
    "    # \"svar\": severe nonkeratinizing dysplastic?\n",
    "    # if we only want to apply provided functions to one type of cell\n",
    "    if abbr:\n",
    "        files = glob.glob(f\"{folder}/{abbr}*\")\n",
    "    else:\n",
    "        files = glob.glob(f\"{folder}/*\")\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    num = 0\n",
    "    sum_msqe = 0\n",
    "    bin_list = []\n",
    "    count_list = []\n",
    "    # open and grayscale each file\n",
    "    for file in files:\n",
    "        num += 1\n",
    "        pix_list = open_in_gray(file)\n",
    "        for func in funcs:\n",
    "            if func[0] == quantizer:\n",
    "                pix_list, msqe = func[0](pix_list, **(func[1]))\n",
    "                sum_msqe += msqe\n",
    "            elif func[0] == hist:\n",
    "                bins, counts = func[0](pix_list, **(func[1]))\n",
    "                bin_list.append(bins)\n",
    "                count_list.append(counts)\n",
    "            else:\n",
    "                pix_list = func[0](pix_list, **(func[1]))\n",
    "        if save_loc:\n",
    "            to_image(pix_list, save_loc=f\"{save_loc}/out{num}.png\")\n",
    "        else:\n",
    "            to_image(pix_list)\n",
    "\n",
    "    if verbose:\n",
    "        # statistics\n",
    "        end = time.perf_counter()\n",
    "        batch = end - start\n",
    "        ind = batch / len(files)\n",
    "        out_string = f\"batch time: {batch}\\naverage individual time: {ind}\"\n",
    "        if quantizer in [func[0] for func in funcs]:\n",
    "            out_string += f\"\\n mean of msqe: {sum_msqe/len(files)}\"\n",
    "    \n",
    "        print(out_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge operator function, can do Prewitt, Sobel, or Jahne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_operator(img, type=\"Jahne\", sharpen_thresh=0):\n",
    "    new_img_x = []\n",
    "    new_img_y = []\n",
    "    if type == \"Prewitt\":\n",
    "        x_mask = [[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]\n",
    "        y_mask = [[-1, -1, -1], [0, 0, 0], [1, 1, 1]]\n",
    "        new_img_x = avg_linear_filter(img, weights=x_mask, sum_weights=6)\n",
    "        new_img_y = avg_linear_filter(img, weights=y_mask, sum_weights=6)\n",
    "    elif type == \"Sobel\":\n",
    "        x_mask = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "        y_mask = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
    "        new_img_x = avg_linear_filter(img, weights=x_mask, sum_weights=8)\n",
    "        new_img_y = avg_linear_filter(img, weights=y_mask, sum_weights=8)\n",
    "    elif type == \"Jahne\":\n",
    "        x_mask = [[-3, 0, 3], [-10, 0, 10], [-3, 0, 3]]\n",
    "        y_mask = [[-3, -10, -3], [0, 0, 0], [3, 10, 3]]\n",
    "        new_img_x = avg_linear_filter(img, weights=x_mask, sum_weights=32)\n",
    "        new_img_y = avg_linear_filter(img, weights=y_mask, sum_weights=32)\n",
    "\n",
    "    length = len(new_img_y)\n",
    "    width = len(new_img_y[0])\n",
    "    new_img = []\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            grad = math.sqrt(new_img_x[i][j]**2 + new_img_y[i][j]**2)\n",
    "            if sharpen_thresh > 0:\n",
    "                if grad > sharpen_thresh:\n",
    "                    new_img[i].append(255)\n",
    "                else:\n",
    "                    new_img[i].append(0)\n",
    "            else:\n",
    "                new_img[i].append(grad)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram thresholding â€“ single threshold that divides image into two segments: foreground (cells) and background (everything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_thresh(img):\n",
    "    bins, counts = hist(img)\n",
    "    num_pix = sum(counts)\n",
    "    within_group_vars = []\n",
    "\n",
    "    for thresh in range(2, 255):\n",
    "        obj_prior = sum(counts[:thresh]) / num_pix\n",
    "        back_prior = sum(counts[thresh:]) / num_pix\n",
    "\n",
    "        if obj_prior != 0:\n",
    "            obj_mean = (sum([i * counts[i] for i in range(thresh)]) / num_pix)\\\n",
    "                / obj_prior\n",
    "            obj_var = sum([(i - obj_mean)**2 * counts[i] for i in range(thresh)])\\\n",
    "                / (num_pix * obj_prior)\n",
    "        else:\n",
    "            obj_var = 0\n",
    "        \n",
    "        if back_prior != 0:\n",
    "            back_mean = (sum([i * counts[i] for i in range(thresh, 255)]) / num_pix)\\\n",
    "                / back_prior\n",
    "            back_var = sum([(i - back_mean)**2 * counts[i] for i in range(thresh, 255)])\\\n",
    "                / (num_pix * back_prior)\n",
    "        else:\n",
    "            back_var = 0\n",
    "\n",
    "        within_group_vars.append(obj_var * obj_prior + back_var * back_prior)\n",
    "    \n",
    "    index = within_group_vars.index(min(within_group_vars))\n",
    "    threshold = bins[index+1]\n",
    "\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "\n",
    "    new_img = []\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            if img[i][j] <= threshold:\n",
    "                new_img[i].append(0)\n",
    "            else:\n",
    "                new_img[i].append(255)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dilation and erosion operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(img, weights):\n",
    "    # use a square filter with 0 for negative (white) and 1 for positive (black)\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    binary = hist_thresh(img)\n",
    "    new_img = []\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            new_img[i].append(255)\n",
    "\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            if binary[i][j] == 0:\n",
    "                for m in range(-mask_radius, mask_radius + 1):\n",
    "                    for n in range(-mask_radius, mask_radius + 1):\n",
    "                        if weights[m+mask_radius][n+mask_radius] == 1\\\n",
    "                            and i + m >= 0 and i + m < length\\\n",
    "                            and j + n > 0 and j + n < width:\n",
    "                            new_img[i+m][j+n] = 0\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode(img, weights):\n",
    "    # use a square filter with 0 for negative (white) and 1 for positive (black)\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    binary = hist_thresh(img)\n",
    "    new_img = []\n",
    "\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            new_img[i].append(255)\n",
    "\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            present = True\n",
    "            for m in range(-mask_radius, mask_radius + 1):\n",
    "                for n in range(-mask_radius, mask_radius + 1):\n",
    "                    if weights[m+mask_radius][n+mask_radius] == 1\\\n",
    "                        and i + m >= 0 and i + m < length\\\n",
    "                        and j + n > 0 and j + n < width:\n",
    "                        if binary[i+m][j+n] != 0:\n",
    "                            present = False\n",
    "                            break\n",
    "                if not present:\n",
    "                    break\n",
    "            if present:    \n",
    "                new_img[i][j] = 0\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_quantize(img, k, iter=10):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "\n",
    "    intensity = random.sample(range(256), k)\n",
    "    centroids = [i for i in intensity]\n",
    "\n",
    "    new_img = []\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            new_img[i].append(0)\n",
    "\n",
    "    for _ in range(iter):\n",
    "        # sums keeps track of the sum for [x, y, intensity] for each centroid\n",
    "        # counts is number of points assigned to each centroid\n",
    "        sums = [0 for _ in range(k)]\n",
    "        counts = [0 for _ in range(k)]\n",
    "\n",
    "        for i in range(length):\n",
    "            for j in range(width):\n",
    "                cent_dist = 9999999999999\n",
    "                closest = 0\n",
    "\n",
    "                for m in range(k):\n",
    "                    int_dist = centroids[m] - img[i][j]\n",
    "                    dist = math.sqrt(int_dist**2)\n",
    "\n",
    "                    if dist < cent_dist:\n",
    "                        cent_dist = dist\n",
    "                        closest = m\n",
    "                \n",
    "                # assign pixels to centroids and update stats for cluster centroids\n",
    "                new_img[i][j] = closest\n",
    "                sums[closest] += img[i][j]\n",
    "                counts[closest] += 1\n",
    "            \n",
    "        # move centroids to avg of assigned pixels\n",
    "        for m in range(k):\n",
    "            if counts[m] != 0:\n",
    "                centroids[m] = sums[m] / counts[m]\n",
    "\n",
    "    colors = list(range(0, 256, math.floor(255/(k - 1))))\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            new_img[i][j] = colors[new_img[i][j]]\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_dist(img, k, iter=10, dist_weight=.25):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    avg_dim = (width + length) / 2\n",
    "\n",
    "    ii = random.sample(range(length), k)\n",
    "    jj = random.sample(range(width), k)\n",
    "    intensity = random.sample(range(256), k)\n",
    "    centroids = [[i, j, inten] for i, j, inten in zip(ii, jj, intensity)]\n",
    "\n",
    "    new_img = [[0 for _ in range(width)] for _ in range(length)]\n",
    "\n",
    "    for _ in range(iter):\n",
    "        # sums keeps track of the sum for [x, y, intensity] for each centroid\n",
    "        # counts is number of points assigned to each centroid\n",
    "        sums = [[0, 0, 0] for _ in range(k)]\n",
    "        counts = [0 for _ in range(k)]\n",
    "\n",
    "        for i in range(length):\n",
    "            for j in range(width):\n",
    "                cent_dist = 9999999999999\n",
    "                closest = 0\n",
    "\n",
    "                for m in range(k):\n",
    "                    i_dist = centroids[m][0] - i\n",
    "                    j_dist = centroids[m][1] - j\n",
    "                    int_dist = centroids[m][2] - img[i][j]\n",
    "\n",
    "                    # intensity is scaled by the avg of the dimensions, distances can be\n",
    "                    # scaled by dist_weight\n",
    "                    dist = math.sqrt((i_dist * dist_weight)**2 + (j_dist * dist_weight)**2\\\n",
    "                        + (int_dist * avg_dim / 255)**2)\n",
    "\n",
    "                    if dist < cent_dist:\n",
    "                        cent_dist = dist\n",
    "                        closest = m\n",
    "                \n",
    "                # assign pixels to centroids and update stats for cluster centroids\n",
    "                new_img[i][j] = closest\n",
    "                sums[closest][0] += i\n",
    "                sums[closest][1] += j\n",
    "                sums[closest][2] += img[i][j]\n",
    "                counts[closest] += 1\n",
    "            \n",
    "        # move centroids to avg of assigned pixels\n",
    "        for m in range(k):\n",
    "            if counts[m] != 0:\n",
    "                centroids[m][0] = sums[m][0] / counts[m]\n",
    "                centroids[m][1] = sums[m][1] / counts[m]\n",
    "                centroids[m][2] = sums[m][2] / counts[m]\n",
    "\n",
    "    colors = list(range(0, 256, math.floor(255/(k - 1))))\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            new_img[i][j] = colors[new_img[i][j]]\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(img, radius=10, min_obj=60):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    avg_dim = (length + width) / 2\n",
    "\n",
    "    new_img = [[0 for _ in range(width)] for _ in range(length)]\n",
    "\n",
    "    cores = []\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            n_nearby = 0\n",
    "            nearby = []\n",
    "            # searching within a circle within a square - there's probably a better way to do this\n",
    "            for m in range(-radius, radius):\n",
    "                for n in range(-radius, radius):\n",
    "                    if i + m >= 0 and j + n >= 0 and i + m < length and j + n < width:\n",
    "                        # scale the intensity distance to image dimensions\n",
    "                        int_dist = (img[i][j] - img[i+m][j+n]) * avg_dim / 255\n",
    "                        if math.sqrt(m**2 + n**2 + int_dist**2) <= radius:\n",
    "                            n_nearby += 1\n",
    "                            nearby.append([i + m, j + n])\n",
    "                            new_img[i+m][j+n] = -1\n",
    "\n",
    "            if n_nearby >= min_obj:\n",
    "                cores.append({\"loc\": [i, j], \"neighbors\": nearby})\n",
    "                new_img[i][j] = -1\n",
    "\n",
    "    clusters = {}\n",
    "    cluster_serial = 0\n",
    "    for core in cores:\n",
    "        # 0 for the pixel value will stand in for \"background\", 1, 2, 3, etc. will be cluster #s\n",
    "        # if we find a background core, make it the start of a new cluster\n",
    "        i = core[\"loc\"][0]\n",
    "        j = core[\"loc\"][1]\n",
    "        if new_img[i][j] == -1:\n",
    "            new_img[i][j] = cluster_serial\n",
    "            clusters[str(cluster_serial)] = [[i, j]]\n",
    "            cluster_serial += 1\n",
    "        # go through the neighbors of the core and add them to the core's cluster if they are background\n",
    "        for point in core[\"neighbors\"]:\n",
    "            m = point[0]\n",
    "            n = point[1]\n",
    "            if new_img[m][n] == -1:\n",
    "                new_img[m][n] = new_img[i][j]\n",
    "                clusters[str(new_img[i][j])].append([m, n])\n",
    "\n",
    "            # if we find a point belonging to a different cluster, add this cluster to that one\n",
    "            elif new_img[m][n] != new_img[i][j]:\n",
    "                temp = str(new_img[i][j])\n",
    "                for nb in clusters[str(new_img[i][j])]:\n",
    "                    new_img[nb[0]][nb[1]] = new_img[m][n]\n",
    "\n",
    "                clusters[str(new_img[m][n])].extend(clusters[temp])\n",
    "                clusters.pop(temp)\n",
    "    if cluster_serial > 0:\n",
    "        step = 255/len(clusters)\n",
    "        colors = list(arange(step, 255 + step, step))\n",
    "        cluster_keys = list(clusters.keys())\n",
    "        for i in range(length):\n",
    "            for j in range(width):\n",
    "                if new_img[i][j] == -1:\n",
    "                    new_img[i][j] = 0\n",
    "                else:\n",
    "                    cluster_index = cluster_keys.index(str(new_img[i][j]))\n",
    "                    new_img[i][j] = colors[cluster_index]\n",
    "\n",
    "    return new_img, len(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "special dbscan that returns the clusters, needs some optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_seg(img, radius=10, min_obj=60):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    avg_dim = (length + width) / 2\n",
    "\n",
    "    new_img = [[0 for _ in range(width)] for _ in range(length)]\n",
    "\n",
    "    cores = []\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            n_nearby = 0\n",
    "            nearby = []\n",
    "            # searching within a circle within a square - there's probably a better way to do this\n",
    "            for m in range(-radius, radius):\n",
    "                for n in range(-radius, radius):\n",
    "                    if i + m >= 0 and j + n >= 0 and i + m < length and j + n < width:\n",
    "                        # scale the intensity distance to image dimensions\n",
    "                        int_dist = (img[i][j] - img[i+m][j+n]) * avg_dim / 255\n",
    "                        if math.sqrt(m**2 + n**2 + int_dist**2) <= radius:\n",
    "                            n_nearby += 1\n",
    "                            nearby.append([i + m, j + n])\n",
    "                            new_img[i+m][j+n] = -1\n",
    "\n",
    "            if n_nearby >= min_obj:\n",
    "                cores.append({\"loc\": [i, j], \"neighbors\": nearby})\n",
    "                new_img[i][j] = -1\n",
    "\n",
    "    clusters = {}\n",
    "    cluster_serial = 0\n",
    "    for core in cores:\n",
    "        # 0 for the pixel value will stand in for \"background\", 1, 2, 3, etc. will be cluster #s\n",
    "        # if we find a background core, make it the start of a new cluster\n",
    "        i = core[\"loc\"][0]\n",
    "        j = core[\"loc\"][1]\n",
    "        if new_img[i][j] == -1:\n",
    "            new_img[i][j] = cluster_serial\n",
    "            clusters[str(cluster_serial)] = [[i, j]]\n",
    "            cluster_serial += 1\n",
    "        # go through the neighbors of the core and add them to the core's cluster if they are background\n",
    "        for point in core[\"neighbors\"]:\n",
    "            m = point[0]\n",
    "            n = point[1]\n",
    "            if new_img[m][n] == -1:\n",
    "                new_img[m][n] = new_img[i][j]\n",
    "                clusters[str(new_img[i][j])].append([m, n])\n",
    "\n",
    "            # if we find a point belonging to a different cluster, add this cluster to that one\n",
    "            elif new_img[m][n] != new_img[i][j]:\n",
    "                temp = str(new_img[i][j])\n",
    "                for nb in clusters[str(new_img[i][j])]:\n",
    "                    new_img[nb[0]][nb[1]] = new_img[m][n]\n",
    "\n",
    "                clusters[str(new_img[m][n])].extend(clusters[temp])\n",
    "                clusters.pop(temp)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_perimeter takes a binary segmented image with objects in black and background in white and returns the length of the outer boundaries of all objects within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perimeter(seg_img):\n",
    "    cross_weights = [[0, 1, 0], [1, 1, 1], [0, 1, 0]]\n",
    "    dilated = dilate(seg_img, weights=cross_weights)\n",
    "    dilated_1d = ravel(dilated) + 255\n",
    "    seg_1d = ravel(seg)\n",
    "    outlines = dilated_1d - seg_1d\n",
    "    negative = outlines - 255\n",
    "    return -sum(negative) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "takes clusters (from dbscan_seg) and returns the area, bounding box top left and bottom right corners, and center of mass for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_area_bbox_com(clusters):\n",
    "    areas = []\n",
    "    bboxs = []\n",
    "    coms = []\n",
    "    for cluster_k in clusters.keys():\n",
    "        num_points = len(clusters[cluster_k])\n",
    "        areas.append(num_points)\n",
    "\n",
    "        j_sum = k_sum = j_max = k_max = 0\n",
    "        j_min = k_min = 100000\n",
    "        for i in range(num_points):\n",
    "            j = clusters[cluster_k][i][0]\n",
    "            k = clusters[cluster_k][i][1]\n",
    "            j_sum += j\n",
    "            k_sum += k\n",
    "            if j < j_min:\n",
    "                j_min = j\n",
    "            if k < k_min:\n",
    "                k_min = k\n",
    "            if j > j_max:\n",
    "                j_max = j\n",
    "            if k > k_max:\n",
    "                k_max = k\n",
    "\n",
    "        # bounding boxes have shape [height, width]\n",
    "        bbox_top_left = [j_min, k_min]\n",
    "        bbox_bottom_right = [j_max, k_max]\n",
    "\n",
    "        center_of_mass = [round(j_sum / num_points), round(k_sum / num_points)]\n",
    "\n",
    "        bboxs.append([bbox_top_left, bbox_bottom_right])\n",
    "        coms.append(center_of_mass)\n",
    "    \n",
    "    return areas, bboxs, coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxs(img, bboxs):\n",
    "    img_draw = copy.deepcopy(img)\n",
    "    for i in range(len(bboxs)):\n",
    "        br_y = bboxs[i][1][0]\n",
    "        tl_y = bboxs[i][0][0]\n",
    "        br_x = bboxs[i][1][1]\n",
    "        tl_x = bboxs[i][0][1]\n",
    "        for j in range(br_y - tl_y):\n",
    "            img_draw[tl_y+j][tl_x] = 125\n",
    "            img_draw[tl_y+j][br_x] = 125\n",
    "        for k in range(br_x - tl_x):\n",
    "            img_draw[tl_y][tl_x+k] = 125\n",
    "            img_draw[br_y][tl_x+k] = 125\n",
    "\n",
    "    img_1d = ravel(img_draw)\n",
    "    output = Image.new(\"L\", [len(img[0]), len(img)])\n",
    "    output.putdata(img_1d)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_clusters(img, bboxs):\n",
    "    # returns list of image patches from bounding boxes\n",
    "    new_images = []\n",
    "    for i in range(len(bboxs)):\n",
    "        new_images.append([])\n",
    "        br_i = bboxs[i][1][0]\n",
    "        tl_i = bboxs[i][0][0]\n",
    "        br_j = bboxs[i][1][1]\n",
    "        tl_j = bboxs[i][0][1]\n",
    "        for j in range(tl_i, br_i + 1):\n",
    "            new_images[i].append([])\n",
    "            for k in range(tl_j, br_j + 1):\n",
    "                try:\n",
    "                    new_images[i][j-tl_i].append(img[j][k])\n",
    "                except:\n",
    "                    print(i, j, k)\n",
    "\n",
    "    \n",
    "    return new_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(img):\n",
    "    height = len(img)\n",
    "    width = len(img[0])\n",
    "\n",
    "    flip_sum_ix = flip_sum_jx = flip_area = 0\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            flip_sum_ix += (img[i][j] - 255) * i\n",
    "            flip_sum_jx += (img[i][j] - 255) * j\n",
    "            flip_area += img[i][j] - 255\n",
    "    area = flip_area\n",
    "    return [flip_sum_ix / area, flip_sum_jx / area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cent_moment(img, com, p, q):\n",
    "    # not entirely sure this is correct\n",
    "    height = len(img)\n",
    "    width = len(img[0])\n",
    "    summed = 0\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            value = abs(img[i][j] - 255) / 255\n",
    "            summed += (i - com[0])**p * (j - com[1])**q * value\n",
    "    return summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cms_orient(img, com):\n",
    "    cm_00 = cent_moment(img, com, 0, 0)\n",
    "    cm_11 = cent_moment(img, com, 1, 1)\n",
    "    cm_02 = cent_moment(img, com, 0, 2)\n",
    "    cm_20 = cent_moment(img, com, 2, 0)\n",
    "\n",
    "    cm_20_prime = cm_20 / cm_00\n",
    "    cm_02_prime = cm_02 / cm_00\n",
    "    cm_11_prime = cm_11 / cm_00\n",
    "\n",
    "    theta = 1/2 * math.atan(2 * cm_11_prime / (cm_20_prime - cm_02_prime))\n",
    "\n",
    "    return cm_11, cm_02, cm_20, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8238117.0 8455672.0 8041897.0 -0.7728440795681144\n"
     ]
    }
   ],
   "source": [
    "# 1st and 2nd central moments and orientation\n",
    "cm_11, cm_02, cm_20, theta = get_cent_moments_orientation(patches[0], coms[0])\n",
    "print(cm_11, cm_02, cm_20, theta)\n",
    "theta/math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_cyl_clean():\n",
    "    img = open_in_gray(\"Cancerous cell smears/cyl01.BMP\")\n",
    "    # get rid of annoying line artifacts on the edges\n",
    "    crop_img = crop(img, 3)\n",
    "    seg = k_means_quantize(crop_img, 2)\n",
    "    # just to clean it up a bit, have to apply hist_thresh cause my code is poorly thought out\n",
    "    eroded = erode(seg, weights=dilate_erode_weights)\n",
    "    clean = dilate(eroded, weights=dilate_erode_weights)\n",
    "\n",
    "    clean = make_bgnd_white_arrayify(clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=762x562 at 0x1253C2700>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = open_cyl_clean()\n",
    "to_image(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = dbscan_seg(clean)\n",
    "# get the background cluster out of there\n",
    "avg_intensities = []\n",
    "keys = []\n",
    "for cluster_k in clusters.keys():\n",
    "    num_points = len(clusters[cluster_k])\n",
    "    sum_intensity = 0\n",
    "    for i in range(num_points):\n",
    "        j = clusters[cluster_k][i][0]\n",
    "        k = clusters[cluster_k][i][1]\n",
    "        sum_intensity += clean[j][k]\n",
    "    avg_intensities.append(sum_intensity / num_points)\n",
    "    keys.append((cluster_k))\n",
    "\n",
    "max_index = avg_intensities.index(max(avg_intensities))\n",
    "clusters.pop(keys[max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bboxs, areas, coms\n",
      "[[154, 158], [185, 184]] 413 [167, 173]\n",
      "[[184, 389], [233, 411]] 378 [207, 400]\n",
      "[[237, 343], [251, 356]] 176 [244, 349]\n",
      "[[249, 279], [384, 436]] 11837 [316, 355]\n",
      "[[395, 143], [416, 157]] 97 [408, 151]\n",
      "[[421, 117], [529, 173]] 4231 [476, 146]\n"
     ]
    }
   ],
   "source": [
    "areas, bboxs, coms = get_area_bbox_com(clusters)\n",
    "patches = cut_clusters(clean, bboxs)\n",
    "draw_bboxs(clean, bboxs).show()\n",
    "print(\"bboxs, areas, coms\")\n",
    "for i in range(len(bboxs)):\n",
    "    print(bboxs[i], areas[i], coms[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats(img):\n",
    "    # all the feature extraction and processing for that, takes a grayscale array image\n",
    "    # get rid of annoying line artifacts on the edges\n",
    "    crop_img = copy.deepcopy([x[3:-3] for x in img[3:-3]])\n",
    "    # binarize image\n",
    "    seg = k_means_quantize(crop_img, 2)\n",
    "    dilate_erode_weights = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]\n",
    "    # clean it up a bit\n",
    "    clean = erode(dilate(seg, weights=dilate_erode_weights), weights=dilate_erode_weights)\n",
    "    print(\"image cleaned, clustering (will take a while)\")\n",
    "\n",
    "    # get object clusters (pixel locations) from image\n",
    "    clusters = dbscan_seg(clean)\n",
    "    print(\"done clustering! extracting cells and features\")\n",
    "    \n",
    "    # get the background cluster out of there\n",
    "    avg_intensities = []\n",
    "    keys = []\n",
    "    for cluster_k in clusters.keys():\n",
    "        num_points = len(clusters[cluster_k])\n",
    "        sum_intensity = 0\n",
    "        for i in range(num_points):\n",
    "            j = clusters[cluster_k][i][0]\n",
    "            k = clusters[cluster_k][i][1]\n",
    "            sum_intensity += clean[j][k]\n",
    "        avg_intensities.append(sum_intensity / num_points)\n",
    "        keys.append((cluster_k))\n",
    "\n",
    "    max_index = avg_intensities.index(max(avg_intensities))\n",
    "    clusters.pop(keys[max_index])\n",
    "\n",
    "    # start retrieving features\n",
    "    areas, bboxs, coms = get_area_bbox_com(clusters)\n",
    "    height = len(img)\n",
    "    width = len(img[0])\n",
    "\n",
    "    # get square patches from segmented image\n",
    "    patches = cut_clusters(clean, bboxs)\n",
    "    perimeters = []\n",
    "    centroids = []\n",
    "    cms_11 = []\n",
    "    cms_20 = []\n",
    "    cms_02 = []\n",
    "    orientations = []\n",
    "    for i, patch in enumerate(patches):\n",
    "        # pad image so dilation to get perimeter works\n",
    "        padded = pad(patch, 3)\n",
    "        perimeters.append(get_perimeter(padded))\n",
    "\n",
    "        # get centroid and center of mass\n",
    "        centroid = get_centroid(patch)\n",
    "        centroids.append([centroid[0] / len(patch), centroid[1] / len(patch[0])])\n",
    "\n",
    "        coms[i] = [coms[i] / height, coms[i] / width]\n",
    "\n",
    "        # 1st and 2nd central moments and orientation\n",
    "        cm_11, cm_02, cm_20, theta = get_cms_orient(patch, coms[i])\n",
    "        cms_11.append(cm_11)\n",
    "        cms_20.append(cm_20)\n",
    "        cms_02.append(cm_02)\n",
    "        orientations.append(theta(img))\n",
    "\n",
    "    return (areas, bboxs, coms, perimeters, centroids, cms_11,\n",
    "    cms_20, cms_02, orientations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image cleaned, clustering (will take a while)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p5/yk17c93s4md4ndj2srhtsk180000gn/T/ipykernel_4275/3130647352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_in_gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cancerous cell smears/svar104.BMP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/p5/yk17c93s4md4ndj2srhtsk180000gn/T/ipykernel_4275/1126535604.py\u001b[0m in \u001b[0;36mget_feats\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# get object clusters (pixel locations) from image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbscan_seg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done clustering! extracting cells and features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p5/yk17c93s4md4ndj2srhtsk180000gn/T/ipykernel_4275/2786022159.py\u001b[0m in \u001b[0;36mdbscan_seg\u001b[0;34m(img, radius, min_obj)\u001b[0m\n\u001b[1;32m     19\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint_dist\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                             \u001b[0mn_nearby\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                             \u001b[0mnearby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                             \u001b[0mnew_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feats = get_feats(open_in_gray(\"Cancerous cell smears/svar104.BMP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
