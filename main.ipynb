{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import statistics as st\n",
    "import random\n",
    "import copy\n",
    "import csv\n",
    "from re import search\n",
    "from numpy import arange, ravel, array\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise addition functions: \n",
    "* Salt and pepper noise of user-specified strength \n",
    "* Gaussian noise of user-specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salt_n_pepper(img, prob):\n",
    "    # prob should be int [0 - 1], recommend <.1\n",
    "    new_img = []\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            if random.random() <= prob:\n",
    "                if random.choice([\"black\", \"white\"]) == \"black\":\n",
    "                    new_img[i].append(0)\n",
    "                else:\n",
    "                    new_img[i].append(255)\n",
    "            else:\n",
    "                new_img[i].append(img[i][j])\n",
    "    return new_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(img, mu=0, sigma=1):\n",
    "    new_img = []\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            new_val = img[i][j] + random.gauss(mu, sigma)\n",
    "            if new_val < 0:\n",
    "                new_img[i].append(0)\n",
    "            elif new_val > 255:\n",
    "                new_img[i].append(1)\n",
    "            else:\n",
    "                new_img[i].append(new_val)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting color images to selected single color spectrum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    new_img = []\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            # CIE recommended constants\n",
    "            grey = .2126 * img[i][j][0] + .7152 * img[i][j][1]+ .0722 * img[i][j][2]\n",
    "            new_img[i].append(grey)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open_in_gray is the only function to open an image as all other functions are for grayscale images. run open_in gray on a file, then a function or functions on the returned image, then to_image on that return to get a viewable image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_in_gray(file):\n",
    "    img = Image.open(file)\n",
    "    width, height = img.size\n",
    "    pix = img.getdata()\n",
    "    pix_list = []\n",
    "    for y in range(height):\n",
    "        row = []\n",
    "        for x in range(width):\n",
    "            value = pix[y * width + x]\n",
    "            row.append(value)\n",
    "        pix_list.append(row)\n",
    "\n",
    "    # all functions are on grayscale, so this step is required\n",
    "    pix_list = grayscale(pix_list)\n",
    "    return pix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_image(pix_list, save_loc=None):\n",
    "    size = [len(pix_list[0]), len(pix_list)]\n",
    "    flat_list = []\n",
    "    for row in pix_list:\n",
    "        for i in range(len(row)):\n",
    "            value = row[i]\n",
    "            flat_list.append(value)\n",
    "    output = Image.new(\"L\", size)\n",
    "    output.putdata(flat_list)\n",
    "    \n",
    "    if save_loc:\n",
    "        output.save(f\"{save_loc}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram calculation for each individual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(img, bins=255):\n",
    "    bin_divs = []\n",
    "    counts = []\n",
    "    for i in range(1, bins + 1):\n",
    "        bin_divs.append(i * 255/bins)\n",
    "        counts.append(0)\n",
    "\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[i])):\n",
    "            # better as a binary search\n",
    "            for k in range(bins):\n",
    "                if img[i][j] <= bin_divs[k]:\n",
    "                    counts[k] += 1\n",
    "                    break\n",
    "    \n",
    "    return bin_divs, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(bin_divs, counts, title=None):\n",
    "    half_width = bin_divs[0]/2\n",
    "    plt.bar([x - half_width for x in bin_divs], counts, width = half_width*2)\n",
    "    plt.xlabel(\"intensity\")\n",
    "    plt.ylabel(\"count\")\n",
    "    if title:\n",
    "            titles = {\"cyl\": \"columnar epithelial\",\n",
    "                    \"para\": \"parabasal squamous epithelial\",\n",
    "                    \"inter\": \"intermediate squamous epithelial\",\n",
    "                    \"super\": \"superficial squamous epithelial\",\n",
    "                    \"let\": \"mild nonkeratinizing dysplastic\",\n",
    "                    \"mod\": \"moderate nonkeratinizing dysplastic\",\n",
    "                    \"svar\": \"severe nonkeratinizing dysplastic\"}\n",
    "            plt.title(titles[title])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaged histograms of pixel values for each class of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hist_avg_class can be run independently of open_in_gray as it runs it internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_avg_class(folder, abbr, bins=255, plot=False):\n",
    "    # abbr can be:\n",
    "    # \"cyl\": columnar epithelial?\n",
    "    # \"para\": parabasal squamous epithelial\n",
    "    # \"inter\": intermediate squamous epithelial\n",
    "    # \"super\": superficial squamous epithelial\n",
    "    # \"let\": mild nonkeratinizing dysplastic?\n",
    "    # \"mod\": moderate nonkeratinizing dysplastic\n",
    "    # \"svar\": severe nonkeratinizing dysplastic?\n",
    "    files = glob.glob(f\"{folder}/{abbr}*\")\n",
    "\n",
    "    bin_divs = [i * 255/bins for i in range(1, bins + 1)]\n",
    "    counts = [0 for _ in range(bins)]\n",
    "    # open and grayscale each file\n",
    "    for file in files:\n",
    "        pix_list = open_in_gray(file)\n",
    "        # get and add counts\n",
    "        _, ind_counts = hist(pix_list, bins = bins)\n",
    "        counts = [a + b for a, b in zip(counts, ind_counts)]\n",
    "\n",
    "    # average counts\n",
    "    counts = [x / len(files) for x in counts]\n",
    "\n",
    "    return bin_divs, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram equalization for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_eq(img):\n",
    "    new_img = []\n",
    "    # get cdf\n",
    "    num_pix = len(img) * len(img[0])\n",
    "    _, counts = hist(img)\n",
    "    cdf = []\n",
    "    sum_int = 0\n",
    "    for i in range(len(counts)):\n",
    "        sum_int += counts[i]\n",
    "        cdf.append(math.floor(255 * sum_int / num_pix))\n",
    "    # apply cdf\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            new_img[i].append(cdf[int(img[i][j])])\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected image quantization technique for user-specified levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizer(img, num_levels):\n",
    "    new_img = []\n",
    "    bins = [i * 255/num_levels for i in range(1, num_levels + 1)]\n",
    "    dQ = 255 / num_levels\n",
    "    msqe = 0\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            for k in range(num_levels):\n",
    "                if img[i][j] <= bins[k]:\n",
    "                    new_img[i].append((k + .5) * dQ)\n",
    "                    msqe += (img[i][j] - new_img[i][j])**2\n",
    "                    break\n",
    "    msqe /= len(img) * len(img[0])\n",
    "\n",
    "    return new_img, msqe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bgnd_white_arrayify(img):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    # evaluate img, if mostly black, flip every pixel\n",
    "    # I assume the background will occupy most of the image\n",
    "    sum_white = sum([sum(img[i]) for i in range(len(img))])\n",
    "    if sum_white / 255 < length * width / 2:\n",
    "        less = ravel(img) - 255\n",
    "        inverted = abs(less)\n",
    "        inverted = inverted.reshape((length, width))\n",
    "    else:\n",
    "        inverted = array(img)\n",
    "    return inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img, amount):\n",
    "    # amount is width in pixels to crop from all edges\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    new_img = []\n",
    "    for i in range(length - 2 * amount):\n",
    "        new_img.append([])\n",
    "        for j in range(width - 2 * amount):\n",
    "            value = img[amount+i][amount+j]\n",
    "            new_img[i].append(value)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(img, amount):\n",
    "    # amount is width in pixels to pad on all edges\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    new_img = []\n",
    "    for i in range(length + 2 * amount):\n",
    "        new_img.append([])\n",
    "        for j in range(width + 2 * amount):\n",
    "            if i >= length + amount or j >= width + amount\\\n",
    "                or i < amount or j < amount:\n",
    "                value = 255\n",
    "            else:\n",
    "                value = img[i-amount][j-amount]\n",
    "            new_img[i].append(value)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_bounds(img, length, width, mask_size):\n",
    "    # works well when there is no border\n",
    "    new_img = []\n",
    "    for i in range(mask_size):\n",
    "        new_img.append([])\n",
    "        # top left corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i].append(img[length-mask_size+i][width-mask_size+j])\n",
    "        # top center\n",
    "        for j in range(width):\n",
    "            new_img[i].append(img[length-mask_size+i][j])\n",
    "        # top right corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i].append(img[length-mask_size+i][j])\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        # middle left\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+mask_size].append(img[i][width-mask_size+j])\n",
    "        # middle center\n",
    "        for j in range(width):\n",
    "            new_img[i+mask_size].append(img[i][j])\n",
    "        # middle right\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+mask_size].append(img[i][j])\n",
    "    for i in range(mask_size):\n",
    "        new_img.append([])\n",
    "        # bottom left corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+length+mask_size].append(img[i][width-mask_size+j])\n",
    "        # bottom center\n",
    "        for j in range(width):\n",
    "            new_img[i+length+mask_size].append(img[i][j])\n",
    "        # bottom right corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+length+mask_size].append(img[i][j])\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering operations: \n",
    "*Linear filter with user-specified mask size and pixel weights\n",
    "*Median filter with user-specified mask size and pixel weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_3x3 = [[1, 2, 1], [2, 4, 2], [1, 2, 1]]\n",
    "gauss_5x5 = [[1, 4, 7, 4, 1], [4, 16, 26, 16, 4], [7, 26, 41, 26, 7],\n",
    "            [4, 16, 26, 16, 4], [1, 4, 7, 4, 1]]\n",
    "dilate_erode_weights = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_linear_filter(img, weights=gauss_5x5, sum_weights=0):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    ext_img = ext_bounds(img, length, width, mask_radius)\n",
    "\n",
    "    # sum_weights can be changed from 0 for an edge detector or other\n",
    "    # filter where the sum would equal 0 and cause zero division error.\n",
    "    # Otherwise, the function will figure it out, below.\n",
    "    if sum_weights == 0:\n",
    "        for i in range(len(weights)):\n",
    "            sum_weights += sum(weights[i])\n",
    "        \n",
    "        if sum_weights == 0:\n",
    "            print(\"please supply a non-zero sum_weights for this filter,\\\n",
    "            maybe the sum of their absolute values.\")\n",
    "    \n",
    "    # apply filter\n",
    "    new_img = []\n",
    "    for i in range(mask_radius, length + mask_radius):\n",
    "        new_img.append([])\n",
    "        for j in range(mask_radius, width + mask_radius):\n",
    "            summed = 0\n",
    "            for k in range(len(weights)):\n",
    "                for m in range(len(weights[k])):\n",
    "                    summed += ext_img[i-mask_radius+k][j-mask_radius+m] *\\\n",
    "                    weights[k][m]\n",
    "            new_img[i-mask_radius].append(summed / sum_weights)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_linear_filter(img, weights=gauss_5x5):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    ext_img = ext_bounds(img, length, width, mask_radius)\n",
    "\n",
    "    # apply filter\n",
    "    new_img = []\n",
    "    for i in range(mask_radius, length + mask_radius):\n",
    "        new_img.append([])\n",
    "        for j in range(mask_radius, width + mask_radius):\n",
    "            products = []\n",
    "            for k in range(len(weights)):\n",
    "                for m in range(len(weights[k])):\n",
    "                    for _ in range(weights[k][m]):\n",
    "                        products.append(ext_img[i-mask_radius+k][j-mask_radius+m])\n",
    "            new_img[i-mask_radius].append(st.median(products))\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(folder, funcs, abbr=None, save_loc=None, verbose=False):\n",
    "    # funcs should be a tuple or list like:\n",
    "    # [[func1, {param1:arg1, param2:arg2}], [func2, {param1:arg1}]]\n",
    "    # where paramaters are anything besides \"img\" or \"folder\"\n",
    "    \n",
    "    # abbr can be:\n",
    "    # \"cyl\": columnar epithelial?\n",
    "    # \"para\": parabasal squamous epithelial\n",
    "    # \"inter\": intermediate squamous epithelial\n",
    "    # \"super\": superficial squamous epithelial\n",
    "    # \"let\": mild nonkeratinizing dysplastic?\n",
    "    # \"mod\": moderate nonkeratinizing dysplastic\n",
    "    # \"svar\": severe nonkeratinizing dysplastic?\n",
    "    # if we only want to apply provided functions to one type of cell\n",
    "    if abbr:\n",
    "        files = glob.glob(f\"{folder}/{abbr}*\")\n",
    "    else:\n",
    "        files = glob.glob(f\"{folder}/*\")\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    num = 0\n",
    "    sum_msqe = 0\n",
    "    bin_list = []\n",
    "    count_list = []\n",
    "    # open and grayscale each file\n",
    "    for file in files:\n",
    "        num += 1\n",
    "        pix_list = open_in_gray(file)\n",
    "        for func in funcs:\n",
    "            if func[0] == quantizer:\n",
    "                pix_list, msqe = func[0](pix_list, **(func[1]))\n",
    "                sum_msqe += msqe\n",
    "            elif func[0] == hist:\n",
    "                bins, counts = func[0](pix_list, **(func[1]))\n",
    "                bin_list.append(bins)\n",
    "                count_list.append(counts)\n",
    "            else:\n",
    "                pix_list = func[0](pix_list, **(func[1]))\n",
    "        if save_loc:\n",
    "            to_image(pix_list, save_loc=f\"{save_loc}/out{num}.png\")\n",
    "        else:\n",
    "            to_image(pix_list)\n",
    "\n",
    "    if verbose:\n",
    "        # statistics\n",
    "        end = time.perf_counter()\n",
    "        batch = end - start\n",
    "        ind = batch / len(files)\n",
    "        out_string = f\"batch time: {batch}\\naverage individual time: {ind}\"\n",
    "        if quantizer in [func[0] for func in funcs]:\n",
    "            out_string += f\"\\n mean of msqe: {sum_msqe/len(files)}\"\n",
    "    \n",
    "        print(out_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge operator function, can do Prewitt, Sobel, or Jahne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_operator(img, type=\"Jahne\", sharpen_thresh=0):\n",
    "    new_img_x = []\n",
    "    new_img_y = []\n",
    "    if type == \"Prewitt\":\n",
    "        x_mask = [[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]\n",
    "        y_mask = [[-1, -1, -1], [0, 0, 0], [1, 1, 1]]\n",
    "        new_img_x = avg_linear_filter(img, weights=x_mask, sum_weights=6)\n",
    "        new_img_y = avg_linear_filter(img, weights=y_mask, sum_weights=6)\n",
    "    elif type == \"Sobel\":\n",
    "        x_mask = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "        y_mask = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
    "        new_img_x = avg_linear_filter(img, weights=x_mask, sum_weights=8)\n",
    "        new_img_y = avg_linear_filter(img, weights=y_mask, sum_weights=8)\n",
    "    elif type == \"Jahne\":\n",
    "        x_mask = [[-3, 0, 3], [-10, 0, 10], [-3, 0, 3]]\n",
    "        y_mask = [[-3, -10, -3], [0, 0, 0], [3, 10, 3]]\n",
    "        new_img_x = avg_linear_filter(img, weights=x_mask, sum_weights=32)\n",
    "        new_img_y = avg_linear_filter(img, weights=y_mask, sum_weights=32)\n",
    "\n",
    "    length = len(new_img_y)\n",
    "    width = len(new_img_y[0])\n",
    "    new_img = []\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            grad = math.sqrt(new_img_x[i][j]**2 + new_img_y[i][j]**2)\n",
    "            if sharpen_thresh > 0:\n",
    "                if grad > sharpen_thresh:\n",
    "                    new_img[i].append(255)\n",
    "                else:\n",
    "                    new_img[i].append(0)\n",
    "            else:\n",
    "                new_img[i].append(grad)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram thresholding â€“ single threshold that divides image into two segments: foreground (cells) and background (everything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_thresh(img):\n",
    "    bins, counts = hist(img)\n",
    "    num_pix = sum(counts)\n",
    "    within_group_vars = []\n",
    "\n",
    "    for thresh in range(2, 255):\n",
    "        obj_prior = sum(counts[:thresh]) / num_pix\n",
    "        back_prior = sum(counts[thresh:]) / num_pix\n",
    "\n",
    "        if obj_prior != 0:\n",
    "            obj_mean = (sum([i * counts[i] for i in range(thresh)]) / num_pix)\\\n",
    "                / obj_prior\n",
    "            obj_var = sum([(i - obj_mean)**2 * counts[i] for i in range(thresh)])\\\n",
    "                / (num_pix * obj_prior)\n",
    "        else:\n",
    "            obj_var = 0\n",
    "        \n",
    "        if back_prior != 0:\n",
    "            back_mean = (sum([i * counts[i] for i in range(thresh, 255)]) / num_pix)\\\n",
    "                / back_prior\n",
    "            back_var = sum([(i - back_mean)**2 * counts[i] for i in range(thresh, 255)])\\\n",
    "                / (num_pix * back_prior)\n",
    "        else:\n",
    "            back_var = 0\n",
    "\n",
    "        within_group_vars.append(obj_var * obj_prior + back_var * back_prior)\n",
    "    \n",
    "    index = within_group_vars.index(min(within_group_vars))\n",
    "    threshold = bins[index+1]\n",
    "\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "\n",
    "    new_img = []\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            if img[i][j] <= threshold:\n",
    "                new_img[i].append(0)\n",
    "            else:\n",
    "                new_img[i].append(255)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dilation and erosion operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(img, weights):\n",
    "    # use a square filter with 0 for negative (white) and 1 for positive (black)\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    binary = hist_thresh(img)\n",
    "    new_img = []\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            new_img[i].append(255)\n",
    "\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            if binary[i][j] == 0:\n",
    "                for m in range(-mask_radius, mask_radius + 1):\n",
    "                    for n in range(-mask_radius, mask_radius + 1):\n",
    "                        if weights[m+mask_radius][n+mask_radius] == 1\\\n",
    "                            and i + m >= 0 and i + m < length\\\n",
    "                            and j + n > 0 and j + n < width:\n",
    "                            new_img[i+m][j+n] = 0\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode(img, weights):\n",
    "    # use a square filter with 0 for negative (white) and 1 for positive (black)\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    binary = hist_thresh(img)\n",
    "    new_img = []\n",
    "\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            new_img[i].append(255)\n",
    "\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            present = True\n",
    "            for m in range(-mask_radius, mask_radius + 1):\n",
    "                for n in range(-mask_radius, mask_radius + 1):\n",
    "                    if weights[m+mask_radius][n+mask_radius] == 1\\\n",
    "                        and i + m >= 0 and i + m < length\\\n",
    "                        and j + n > 0 and j + n < width:\n",
    "                        if binary[i+m][j+n] != 0:\n",
    "                            present = False\n",
    "                            break\n",
    "                if not present:\n",
    "                    break\n",
    "            if present:    \n",
    "                new_img[i][j] = 0\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_quantize(img, k, iter=10):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "\n",
    "    intensity = random.sample(range(256), k)\n",
    "    centroids = [i for i in intensity]\n",
    "\n",
    "    new_img = []\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            new_img[i].append(0)\n",
    "\n",
    "    for _ in range(iter):\n",
    "        # sums keeps track of the sum for [x, y, intensity] for each centroid\n",
    "        # counts is number of points assigned to each centroid\n",
    "        sums = [0 for _ in range(k)]\n",
    "        counts = [0 for _ in range(k)]\n",
    "\n",
    "        for i in range(length):\n",
    "            for j in range(width):\n",
    "                cent_dist = 9999999999999\n",
    "                closest = 0\n",
    "\n",
    "                for m in range(k):\n",
    "                    int_dist = centroids[m] - img[i][j]\n",
    "                    dist = math.sqrt(int_dist**2)\n",
    "\n",
    "                    if dist < cent_dist:\n",
    "                        cent_dist = dist\n",
    "                        closest = m\n",
    "                \n",
    "                # assign pixels to centroids and update stats for cluster centroids\n",
    "                new_img[i][j] = closest\n",
    "                sums[closest] += img[i][j]\n",
    "                counts[closest] += 1\n",
    "            \n",
    "        # move centroids to avg of assigned pixels\n",
    "        for m in range(k):\n",
    "            if counts[m] != 0:\n",
    "                centroids[m] = sums[m] / counts[m]\n",
    "\n",
    "    colors = list(range(0, 256, math.floor(255/(k - 1))))\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            new_img[i][j] = colors[new_img[i][j]]\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_dist(img, k, iter=10, dist_weight=.25):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    avg_dim = (width + length) / 2\n",
    "\n",
    "    ii = random.sample(range(length), k)\n",
    "    jj = random.sample(range(width), k)\n",
    "    intensity = random.sample(range(256), k)\n",
    "    centroids = [[i, j, inten] for i, j, inten in zip(ii, jj, intensity)]\n",
    "\n",
    "    new_img = [[0 for _ in range(width)] for _ in range(length)]\n",
    "\n",
    "    for _ in range(iter):\n",
    "        # sums keeps track of the sum for [x, y, intensity] for each centroid\n",
    "        # counts is number of points assigned to each centroid\n",
    "        sums = [[0, 0, 0] for _ in range(k)]\n",
    "        counts = [0 for _ in range(k)]\n",
    "\n",
    "        for i in range(length):\n",
    "            for j in range(width):\n",
    "                cent_dist = 9999999999999\n",
    "                closest = 0\n",
    "\n",
    "                for m in range(k):\n",
    "                    i_dist = centroids[m][0] - i\n",
    "                    j_dist = centroids[m][1] - j\n",
    "                    int_dist = centroids[m][2] - img[i][j]\n",
    "\n",
    "                    # intensity is scaled by the avg of the dimensions, distances can be\n",
    "                    # scaled by dist_weight\n",
    "                    dist = math.sqrt((i_dist * dist_weight)**2 + (j_dist * dist_weight)**2\\\n",
    "                        + (int_dist * avg_dim / 255)**2)\n",
    "\n",
    "                    if dist < cent_dist:\n",
    "                        cent_dist = dist\n",
    "                        closest = m\n",
    "                \n",
    "                # assign pixels to centroids and update stats for cluster centroids\n",
    "                new_img[i][j] = closest\n",
    "                sums[closest][0] += i\n",
    "                sums[closest][1] += j\n",
    "                sums[closest][2] += img[i][j]\n",
    "                counts[closest] += 1\n",
    "            \n",
    "        # move centroids to avg of assigned pixels\n",
    "        for m in range(k):\n",
    "            if counts[m] != 0:\n",
    "                centroids[m][0] = sums[m][0] / counts[m]\n",
    "                centroids[m][1] = sums[m][1] / counts[m]\n",
    "                centroids[m][2] = sums[m][2] / counts[m]\n",
    "\n",
    "    colors = list(range(0, 256, math.floor(255/(k - 1))))\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            new_img[i][j] = colors[new_img[i][j]]\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(img, radius=10, min_obj=60):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    avg_dim = (length + width) / 2\n",
    "\n",
    "    new_img = [[0 for _ in range(width)] for _ in range(length)]\n",
    "\n",
    "    cores = []\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            n_nearby = 0\n",
    "            nearby = []\n",
    "            # searching within a circle within a square - there's probably a better way to do this\n",
    "            for m in range(-radius, radius):\n",
    "                for n in range(-radius, radius):\n",
    "                    if i + m >= 0 and j + n >= 0 and i + m < length and j + n < width:\n",
    "                        # scale the intensity distance to image dimensions\n",
    "                        int_dist = (img[i][j] - img[i+m][j+n]) * avg_dim / 255\n",
    "                        if math.sqrt(m**2 + n**2 + int_dist**2) <= radius:\n",
    "                            n_nearby += 1\n",
    "                            nearby.append([i + m, j + n])\n",
    "                            new_img[i+m][j+n] = -1\n",
    "\n",
    "            if n_nearby >= min_obj:\n",
    "                cores.append({\"loc\": [i, j], \"neighbors\": nearby})\n",
    "                new_img[i][j] = -1\n",
    "\n",
    "    clusters = {}\n",
    "    cluster_serial = 0\n",
    "    for core in cores:\n",
    "        # 0 for the pixel value will stand in for \"background\", 1, 2, 3, etc. will be cluster #s\n",
    "        # if we find a background core, make it the start of a new cluster\n",
    "        i = core[\"loc\"][0]\n",
    "        j = core[\"loc\"][1]\n",
    "        if new_img[i][j] == -1:\n",
    "            new_img[i][j] = cluster_serial\n",
    "            clusters[str(cluster_serial)] = [[i, j]]\n",
    "            cluster_serial += 1\n",
    "        # go through the neighbors of the core and add them to the core's cluster if they are background\n",
    "        for point in core[\"neighbors\"]:\n",
    "            m = point[0]\n",
    "            n = point[1]\n",
    "            if new_img[m][n] == -1:\n",
    "                new_img[m][n] = new_img[i][j]\n",
    "                clusters[str(new_img[i][j])].append([m, n])\n",
    "\n",
    "            # if we find a point belonging to a different cluster, add this cluster to that one\n",
    "            elif new_img[m][n] != new_img[i][j]:\n",
    "                temp = str(new_img[i][j])\n",
    "                for nb in clusters[str(new_img[i][j])]:\n",
    "                    new_img[nb[0]][nb[1]] = new_img[m][n]\n",
    "\n",
    "                clusters[str(new_img[m][n])].extend(clusters[temp])\n",
    "                clusters.pop(temp)\n",
    "    if cluster_serial > 0:\n",
    "        step = 255/len(clusters)\n",
    "        colors = list(arange(step, 255 + step, step))\n",
    "        cluster_keys = list(clusters.keys())\n",
    "        for i in range(length):\n",
    "            for j in range(width):\n",
    "                if new_img[i][j] == -1:\n",
    "                    new_img[i][j] = 0\n",
    "                else:\n",
    "                    cluster_index = cluster_keys.index(str(new_img[i][j]))\n",
    "                    new_img[i][j] = colors[cluster_index]\n",
    "\n",
    "    return new_img, len(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "special dbscan that returns the clusters, needs some optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_seg(img, radius=10, min_obj=60):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    avg_dim = (length + width) / 2\n",
    "\n",
    "    new_img = [[0 for _ in range(width)] for _ in range(length)]\n",
    "\n",
    "    cores = []\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            n_nearby = 0\n",
    "            nearby = []\n",
    "            # searching within a circle within a square - there's probably a better way to do this\n",
    "            for m in range(-radius, radius):\n",
    "                for n in range(-radius, radius):\n",
    "                    if i + m >= 0 and j + n >= 0 and i + m < length and j + n < width:\n",
    "                        # scale the intensity distance to image dimensions\n",
    "                        int_dist = (img[i][j] - img[i+m][j+n]) * avg_dim / 255\n",
    "                        if math.sqrt(m**2 + n**2 + int_dist**2) <= radius:\n",
    "                            n_nearby += 1\n",
    "                            nearby.append([i + m, j + n])\n",
    "                            new_img[i+m][j+n] = -1\n",
    "\n",
    "            if n_nearby >= min_obj:\n",
    "                cores.append({\"loc\": [i, j], \"neighbors\": nearby})\n",
    "                new_img[i][j] = -1\n",
    "\n",
    "    clusters = {}\n",
    "    cluster_serial = 0\n",
    "    for core in cores:\n",
    "        # 0 for the pixel value will stand in for \"background\", 1, 2, 3, etc. will be cluster #s\n",
    "        # if we find a background core, make it the start of a new cluster\n",
    "        i = core[\"loc\"][0]\n",
    "        j = core[\"loc\"][1]\n",
    "        if new_img[i][j] == -1:\n",
    "            new_img[i][j] = cluster_serial\n",
    "            clusters[str(cluster_serial)] = [[i, j]]\n",
    "            cluster_serial += 1\n",
    "        # go through the neighbors of the core and add them to the core's cluster if they are background\n",
    "        for point in core[\"neighbors\"]:\n",
    "            m = point[0]\n",
    "            n = point[1]\n",
    "            if new_img[m][n] == -1:\n",
    "                new_img[m][n] = new_img[i][j]\n",
    "                clusters[str(new_img[i][j])].append([m, n])\n",
    "\n",
    "            # if we find a point belonging to a different cluster, add this cluster to that one\n",
    "            elif new_img[m][n] != new_img[i][j]:\n",
    "                temp = str(new_img[i][j])\n",
    "                for nb in clusters[str(new_img[i][j])]:\n",
    "                    new_img[nb[0]][nb[1]] = new_img[m][n]\n",
    "\n",
    "                clusters[str(new_img[m][n])].extend(clusters[temp])\n",
    "                clusters.pop(temp)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_perimeter takes a binary segmented image with objects in black and background in white and returns the length of the outer boundaries of all objects within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perimeter(seg_img):\n",
    "    cross_weights = [[0, 1, 0], [1, 1, 1], [0, 1, 0]]\n",
    "    dilated = dilate(seg_img, weights=cross_weights)\n",
    "    dilated_1d = ravel(dilated) + 255\n",
    "    seg_1d = ravel(seg_img)\n",
    "    outlines = dilated_1d - seg_1d\n",
    "    negative = outlines - 255\n",
    "    return -sum(negative) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "takes clusters (from dbscan_seg) and returns the area, bounding box top left and bottom right corners, and center of mass for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_area_bbox_com(clusters):\n",
    "    areas = []\n",
    "    bboxs = []\n",
    "    coms = []\n",
    "    for cluster_k in clusters.keys():\n",
    "        num_points = len(clusters[cluster_k])\n",
    "        areas.append(num_points)\n",
    "\n",
    "        j_sum = k_sum = j_max = k_max = 0\n",
    "        j_min = k_min = 100000\n",
    "        for i in range(num_points):\n",
    "            j = clusters[cluster_k][i][0]\n",
    "            k = clusters[cluster_k][i][1]\n",
    "            j_sum += j\n",
    "            k_sum += k\n",
    "            if j < j_min:\n",
    "                j_min = j\n",
    "            if k < k_min:\n",
    "                k_min = k\n",
    "            if j > j_max:\n",
    "                j_max = j\n",
    "            if k > k_max:\n",
    "                k_max = k\n",
    "\n",
    "        # bounding boxes have shape [height, width]\n",
    "        bbox_top_left = [j_min, k_min]\n",
    "        bbox_bottom_right = [j_max, k_max]\n",
    "\n",
    "        center_of_mass = [round(j_sum / num_points), round(k_sum / num_points)]\n",
    "\n",
    "        bboxs.append([bbox_top_left, bbox_bottom_right])\n",
    "        coms.append(center_of_mass)\n",
    "    \n",
    "    return areas, bboxs, coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxs(img, bboxs):\n",
    "    img_draw = copy.deepcopy(img)\n",
    "    for i in range(len(bboxs)):\n",
    "        br_y = bboxs[i][1][0]\n",
    "        tl_y = bboxs[i][0][0]\n",
    "        br_x = bboxs[i][1][1]\n",
    "        tl_x = bboxs[i][0][1]\n",
    "        for j in range(br_y - tl_y):\n",
    "            img_draw[tl_y+j][tl_x] = 125\n",
    "            img_draw[tl_y+j][br_x] = 125\n",
    "        for k in range(br_x - tl_x):\n",
    "            img_draw[tl_y][tl_x+k] = 125\n",
    "            img_draw[br_y][tl_x+k] = 125\n",
    "\n",
    "    img_1d = ravel(img_draw)\n",
    "    output = Image.new(\"L\", [len(img[0]), len(img)])\n",
    "    output.putdata(img_1d)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_clusters(img, bboxs):\n",
    "    # returns list of image patches from bounding boxes\n",
    "    new_images = []\n",
    "    for i in range(len(bboxs)):\n",
    "        new_images.append([])\n",
    "        br_i = bboxs[i][1][0]\n",
    "        tl_i = bboxs[i][0][0]\n",
    "        br_j = bboxs[i][1][1]\n",
    "        tl_j = bboxs[i][0][1]\n",
    "        for j in range(tl_i, br_i + 1):\n",
    "            new_images[i].append([])\n",
    "            for k in range(tl_j, br_j + 1):\n",
    "                try:\n",
    "                    new_images[i][j-tl_i].append(img[j][k])\n",
    "                except:\n",
    "                    print(i, j, k)\n",
    "\n",
    "    \n",
    "    return new_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(img):\n",
    "    height = len(img)\n",
    "    width = len(img[0])\n",
    "\n",
    "    flip_sum_ix = flip_sum_jx = flip_area = 0\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            flip_sum_ix += (img[i][j] - 255) * i\n",
    "            flip_sum_jx += (img[i][j] - 255) * j\n",
    "            flip_area += img[i][j] - 255\n",
    "    area = flip_area\n",
    "    return [flip_sum_ix / area, flip_sum_jx / area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cent_moment(img, com, p, q):\n",
    "    # not entirely sure this is correct\n",
    "    height = len(img)\n",
    "    width = len(img[0])\n",
    "    summed = 0\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            value = abs(img[i][j] - 255) / 255\n",
    "            summed += (i - com[0])**p * (j - com[1])**q * value\n",
    "    return summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cms_orient(img, com):\n",
    "    cm_00 = cent_moment(img, com, 0, 0)\n",
    "    cm_11 = cent_moment(img, com, 1, 1)\n",
    "    cm_02 = cent_moment(img, com, 0, 2)\n",
    "    cm_20 = cent_moment(img, com, 2, 0)\n",
    "\n",
    "    cm_20_prime = cm_20 / cm_00\n",
    "    cm_02_prime = cm_02 / cm_00\n",
    "    cm_11_prime = cm_11 / cm_00\n",
    "\n",
    "    theta = 1/2 * math.atan(2 * cm_11_prime / (cm_20_prime - cm_02_prime))\n",
    "\n",
    "    return cm_11, cm_02, cm_20, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8238117.0 8455672.0 8041897.0 -0.7728440795681144\n"
     ]
    }
   ],
   "source": [
    "# 1st and 2nd central moments and orientation\n",
    "cm_11, cm_02, cm_20, theta = get_cent_moments_orientation(patches[0], coms[0])\n",
    "print(cm_11, cm_02, cm_20, theta)\n",
    "theta/math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_cyl_clean():\n",
    "    img = open_in_gray(\"Cancerous cell smears/svar104.BMP\")\n",
    "    # get rid of annoying line artifacts on the edges\n",
    "    crop_img = crop(img, 3)\n",
    "    seg = k_means_quantize(crop_img, 2)\n",
    "    # just to clean it up a bit, have to apply hist_thresh cause my code is poorly thought out\n",
    "    eroded = erode(seg, weights=dilate_erode_weights)\n",
    "    clean = dilate(eroded, weights=dilate_erode_weights)\n",
    "\n",
    "    clean = make_bgnd_white_arrayify(clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=762x562>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = open_cyl_clean()\n",
    "to_image(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gabrielsalmon/Desktop/other_programs/image_analysis/main.ipynb Cell 58'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gabrielsalmon/Desktop/other_programs/image_analysis/main.ipynb#ch0000057?line=0'>1</a>\u001b[0m clusters \u001b[39m=\u001b[39m dbscan_seg(clean)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gabrielsalmon/Desktop/other_programs/image_analysis/main.ipynb#ch0000057?line=1'>2</a>\u001b[0m \u001b[39m# get the background cluster out of there\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gabrielsalmon/Desktop/other_programs/image_analysis/main.ipynb#ch0000057?line=2'>3</a>\u001b[0m avg_intensities \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m/Users/gabrielsalmon/Desktop/other_programs/image_analysis/main.ipynb Cell 44'\u001b[0m in \u001b[0;36mdbscan_seg\u001b[0;34m(img, radius, min_obj)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gabrielsalmon/Desktop/other_programs/image_analysis/main.ipynb#ch0000043?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m-\u001b[39mradius, radius):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gabrielsalmon/Desktop/other_programs/image_analysis/main.ipynb#ch0000043?line=15'>16</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m+\u001b[39m m \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m j \u001b[39m+\u001b[39m n \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i \u001b[39m+\u001b[39m m \u001b[39m<\u001b[39m length \u001b[39mand\u001b[39;00m j \u001b[39m+\u001b[39m n \u001b[39m<\u001b[39m width:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gabrielsalmon/Desktop/other_programs/image_analysis/main.ipynb#ch0000043?line=16'>17</a>\u001b[0m         \u001b[39m# scale the intensity distance to image dimensions\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gabrielsalmon/Desktop/other_programs/image_analysis/main.ipynb#ch0000043?line=17'>18</a>\u001b[0m         int_dist \u001b[39m=\u001b[39m (img[i][j] \u001b[39m-\u001b[39;49m img[i\u001b[39m+\u001b[39;49mm][j\u001b[39m+\u001b[39;49mn]) \u001b[39m*\u001b[39;49m avg_dim \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gabrielsalmon/Desktop/other_programs/image_analysis/main.ipynb#ch0000043?line=18'>19</a>\u001b[0m         \u001b[39mif\u001b[39;00m math\u001b[39m.\u001b[39msqrt(m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m n\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m int_dist\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m radius:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gabrielsalmon/Desktop/other_programs/image_analysis/main.ipynb#ch0000043?line=19'>20</a>\u001b[0m             n_nearby \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clusters = dbscan_seg(clean)\n",
    "# get the background cluster out of there\n",
    "avg_intensities = []\n",
    "keys = []\n",
    "for cluster_k in clusters.keys():\n",
    "    num_points = len(clusters[cluster_k])\n",
    "    sum_intensity = 0\n",
    "    for i in range(num_points):\n",
    "        j = clusters[cluster_k][i][0]\n",
    "        k = clusters[cluster_k][i][1]\n",
    "        sum_intensity += clean[j][k]\n",
    "    avg_intensities.append(sum_intensity / num_points)\n",
    "    keys.append((cluster_k))\n",
    "\n",
    "max_index = avg_intensities.index(max(avg_intensities))\n",
    "clusters.pop(keys[max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=762x562>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_bboxs(clean, feats[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "area 13593\n",
      "bbox [[230, 0], [360, 150]]\n",
      "com [0.5158450704225352, 0.09635416666666667]\n",
      "perimeter 663.0\n",
      "centroid [0.4851229108518008, 0.4876608221256236]\n",
      "cm_11 68352006.03141509\n",
      "cm_20 66774110.32093103\n",
      "cm_02 94998819.90291218\n",
      "orientation -0.6835957037939426\n",
      "1\n",
      "area 8453\n",
      "bbox [[257, 323], [380, 447]]\n",
      "com [0.5616197183098591, 0.5013020833333334]\n",
      "perimeter 624.0\n",
      "centroid [0.5017351969291116, 0.4926775490891886]\n",
      "cm_11 28777190.79060758\n",
      "cm_20 40842320.65608851\n",
      "cm_02 37950154.696624465\n",
      "orientation 0.7602937737425509\n",
      "2\n",
      "area 276\n",
      "bbox [[381, 0], [420, 21]]\n",
      "com [0.7112676056338029, 0.010416666666666666]\n",
      "perimeter 151.0\n",
      "centroid [0.5632246376811594, 0.3769762845849802]\n",
      "cm_11 55015.18251173708\n",
      "cm_20 144400.30489982123\n",
      "cm_02 27925.342447916664\n",
      "orientation 0.37847676890460247\n"
     ]
    }
   ],
   "source": [
    "names = ['area', 'bbox', 'com', 'perimeter', 'centroid', 'cm_11', 'cm_20', 'cm_02', 'orientation', 'class']\n",
    "for i in range(len(feats[1])):\n",
    "    print(i)\n",
    "    for j in range(len(feats) - 2):\n",
    "        print(names[j], feats[j][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats(img):\n",
    "    # all the feature extraction and processing for that, takes a grayscale array image\n",
    "    # get rid of annoying line artifacts on the edges\n",
    "    crop_img = copy.deepcopy([x[3:-3] for x in img[3:-3]])\n",
    "    # binarize image\n",
    "    seg = k_means_quantize(crop_img, 2)\n",
    "    dilate_erode_weights = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]\n",
    "    # clean it up a bit\n",
    "    eroded = erode(seg, weights=dilate_erode_weights)\n",
    "    clean = dilate(eroded, weights=dilate_erode_weights)\n",
    "\n",
    "    # make the largest cluster, probably the background, white so dbscan_seg will ignore it\n",
    "    clean = make_bgnd_white_arrayify(clean)\n",
    "    print(\"image cleaned, clustering (will take a while)\")\n",
    "\n",
    "    # get object clusters (pixel locations) from image\n",
    "    clusters = dbscan_seg(clean)\n",
    "    print(\"done clustering! extracting cells and features\")\n",
    "    \n",
    "    # get the background cluster out of there\n",
    "    avg_intensities = []\n",
    "    keys = []\n",
    "    for cluster_k in clusters.keys():\n",
    "        num_points = len(clusters[cluster_k])\n",
    "        sum_intensity = 0\n",
    "        for i in range(num_points):\n",
    "            j = clusters[cluster_k][i][0]\n",
    "            k = clusters[cluster_k][i][1]\n",
    "            sum_intensity += clean[j][k]\n",
    "        avg_intensities.append(sum_intensity / num_points)\n",
    "        keys.append((cluster_k))\n",
    "\n",
    "    max_index = avg_intensities.index(max(avg_intensities))\n",
    "    clusters.pop(keys[max_index])\n",
    "\n",
    "    # start retrieving features\n",
    "    areas, bboxs, coms = get_area_bbox_com(clusters)\n",
    "    height = len(img)\n",
    "    width = len(img[0])\n",
    "\n",
    "    # get square patches from segmented image\n",
    "    patches = cut_clusters(clean, bboxs)\n",
    "    perimeters = []\n",
    "    centroids = []\n",
    "    cms_11 = []\n",
    "    cms_20 = []\n",
    "    cms_02 = []\n",
    "    orientations = []\n",
    "    for i, patch in enumerate(patches):\n",
    "        # pad image so dilation to get perimeter works\n",
    "        padded = pad(patch, 3)\n",
    "        perimeters.append(get_perimeter(padded))\n",
    "\n",
    "        # get centroid and center of mass\n",
    "        centroid = get_centroid(patch)\n",
    "        centroids.append([centroid[0] / len(patch), centroid[1] / len(patch[0])])\n",
    "\n",
    "        coms[i] = [coms[i][0] / height, coms[i][1] / width]\n",
    "\n",
    "        # 1st and 2nd central moments and orientation\n",
    "        cm_11, cm_02, cm_20, theta = get_cms_orient(patch, coms[i])\n",
    "        cms_11.append(cm_11)\n",
    "        cms_20.append(cm_20)\n",
    "        cms_02.append(cm_02)\n",
    "        orientations.append(theta)\n",
    "\n",
    "    return (areas, bboxs, coms, perimeters, centroids, cms_11,\n",
    "    cms_20, cms_02, orientations, clean, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image cleaned, clustering (will take a while)\n",
      "done clustering! extracting cells and features\n"
     ]
    }
   ],
   "source": [
    "feats = get_feats(open_in_gray(\"Cancerous cell smears/svar104.BMP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a csv\n",
    "with open(\"cells.csv\", 'w') as f:\n",
    "    cells_writer = csv.writer(f)\n",
    "    cells_writer.writerow('area', 'bbox', 'com', 'perimeter', 'centroid', 'cm_11', 'cm_20', 'cm_02', 'orientation', 'class')\n",
    "    \n",
    "    paths = glob.glob(f\"Cancerous cell smears/*\")\n",
    "    for path in paths:\n",
    "        feats = get_feats(path)\n",
    "        for i in range(len(areas)):\n",
    "            cells_writer.writerow(*feats, search('/\\D*', path).group(0)[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(X, y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cf590adf64b12f100e2631293f66eedf21812d31d21d345d3dafaac5b13c0f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
