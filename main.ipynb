{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import statistics as st\n",
    "import random\n",
    "import copy\n",
    "from numpy import arange, ravel\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise addition functions: \n",
    "* Salt and pepper noise of user-specified strength \n",
    "* Gaussian noise of user-specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salt_n_pepper(img, prob):\n",
    "    # prob should be int [0 - 1], recommend <.1\n",
    "    new_img = []\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            if random.random() <= prob:\n",
    "                if random.choice([\"black\", \"white\"]) == \"black\":\n",
    "                    new_img[i].append(0)\n",
    "                else:\n",
    "                    new_img[i].append(255)\n",
    "            else:\n",
    "                new_img[i].append(img[i][j])\n",
    "    return new_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(img, mu=0, sigma=1):\n",
    "    new_img = []\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            new_val = img[i][j] + random.gauss(mu, sigma)\n",
    "            if new_val < 0:\n",
    "                new_img[i].append(0)\n",
    "            elif new_val > 255:\n",
    "                new_img[i].append(1)\n",
    "            else:\n",
    "                new_img[i].append(new_val)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting color images to selected single color spectrum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    new_img = []\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            # CIE recommended constants\n",
    "            grey = .2126 * img[i][j][0] + .7152 * img[i][j][1]+ .0722 * img[i][j][2]\n",
    "            new_img[i].append(grey)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open_in_gray is the only function to open an image as all other functions are for grayscale images. run open_in gray on a file, then a function or functions on the returned image, then to_image on that return to get a viewable image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_in_gray(file):\n",
    "    img = Image.open(file)\n",
    "    width, height = img.size\n",
    "    pix = img.getdata()\n",
    "    pix_list = []\n",
    "    for y in range(height):\n",
    "        pix_list.append([pix[y * width + x] for x in range(width)])\n",
    "\n",
    "    # all functions are on grayscale, so this step is required\n",
    "    pix_list = grayscale(pix_list)\n",
    "    return pix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_image(pix_list, save_loc=None):\n",
    "    size = [len(pix_list[0]), len(pix_list)]\n",
    "    flat_list = []\n",
    "    for row in pix_list:\n",
    "        for pixel in row:\n",
    "            flat_list.append(pixel)\n",
    "    output = Image.new(\"L\", size)\n",
    "    output.putdata(flat_list)\n",
    "    \n",
    "    if save_loc:\n",
    "        output.save(f\"{save_loc}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram calculation for each individual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(img, bins=255):\n",
    "    bin_divs = []\n",
    "    counts = []\n",
    "    for i in range(1, bins + 1):\n",
    "        bin_divs.append(i * 255/bins)\n",
    "        counts.append(0)\n",
    "\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[i])):\n",
    "            # better as a binary search\n",
    "            for k in range(bins):\n",
    "                if img[i][j] <= bin_divs[k]:\n",
    "                    counts[k] += 1\n",
    "                    break\n",
    "    \n",
    "    return bin_divs, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(bin_divs, counts, title=None):\n",
    "    half_width = bin_divs[0]/2\n",
    "    plt.bar([x - half_width for x in bin_divs], counts, width = half_width*2)\n",
    "    plt.xlabel(\"intensity\")\n",
    "    plt.ylabel(\"count\")\n",
    "    if title:\n",
    "            titles = {\"cyl\": \"columnar epithelial\",\n",
    "                    \"para\": \"parabasal squamous epithelial\",\n",
    "                    \"inter\": \"intermediate squamous epithelial\",\n",
    "                    \"super\": \"superficial squamous epithelial\",\n",
    "                    \"let\": \"mild nonkeratinizing dysplastic\",\n",
    "                    \"mod\": \"moderate nonkeratinizing dysplastic\",\n",
    "                    \"svar\": \"severe nonkeratinizing dysplastic\"}\n",
    "            plt.title(titles[title])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaged histograms of pixel values for each class of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hist_avg_class can be run independently of open_in_gray as it runs it internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_avg_class(folder, abbr, bins=255, plot=False):\n",
    "    # abbr can be:\n",
    "    # \"cyl\": columnar epithelial?\n",
    "    # \"para\": parabasal squamous epithelial\n",
    "    # \"inter\": intermediate squamous epithelial\n",
    "    # \"super\": superficial squamous epithelial\n",
    "    # \"let\": mild nonkeratinizing dysplastic?\n",
    "    # \"mod\": moderate nonkeratinizing dysplastic\n",
    "    # \"svar\": severe nonkeratinizing dysplastic?\n",
    "    files = glob.glob(f\"{folder}/{abbr}*\")\n",
    "\n",
    "    bin_divs = [i * 255/bins for i in range(1, bins + 1)]\n",
    "    counts = [0 for _ in range(bins)]\n",
    "    # open and grayscale each file\n",
    "    for file in files:\n",
    "        pix_list = open_in_gray(file)\n",
    "        # get and add counts\n",
    "        _, ind_counts = hist(pix_list, bins = bins)\n",
    "        counts = [a + b for a, b in zip(counts, ind_counts)]\n",
    "\n",
    "    # average counts\n",
    "    counts = [x / len(files) for x in counts]\n",
    "\n",
    "    return bin_divs, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram equalization for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_eq(img):\n",
    "    new_img = []\n",
    "    # get cdf\n",
    "    num_pix = len(img) * len(img[0])\n",
    "    _, counts = hist(img)\n",
    "    cdf = []\n",
    "    sum_int = 0\n",
    "    for i in range(len(counts)):\n",
    "        sum_int += counts[i]\n",
    "        cdf.append(math.floor(255 * sum_int / num_pix))\n",
    "    # apply cdf\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            new_img[i].append(cdf[int(img[i][j])])\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected image quantization technique for user-specified levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizer(img, num_levels):\n",
    "    new_img = []\n",
    "    bins = [i * 255/num_levels for i in range(1, num_levels + 1)]\n",
    "    dQ = 255 / num_levels\n",
    "    msqe = 0\n",
    "    for i in range(len(img)):\n",
    "        new_img.append([])\n",
    "        for j in range(len(img[i])):\n",
    "            for k in range(num_levels):\n",
    "                if img[i][j] <= bins[k]:\n",
    "                    new_img[i].append((k + .5) * dQ)\n",
    "                    msqe += (img[i][j] - new_img[i][j])**2\n",
    "                    break\n",
    "    msqe /= len(img) * len(img[0])\n",
    "\n",
    "    return new_img, msqe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering operations: \n",
    "*Linear filter with user-specified mask size and pixel weights\n",
    "*Median filter with user-specified mask size and pixel weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_bounds(img, length, width, mask_size):\n",
    "    # works well when there is no border\n",
    "    new_img = []\n",
    "    for i in range(mask_size):\n",
    "        new_img.append([])\n",
    "        # top left corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i].append(img[length-mask_size+i][width-mask_size+j])\n",
    "        # top center\n",
    "        for j in range(width):\n",
    "            new_img[i].append(img[length-mask_size+i][j])\n",
    "        # top right corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i].append(img[length-mask_size+i][j])\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        # middle left\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+mask_size].append(img[i][width-mask_size+j])\n",
    "        # middle center\n",
    "        for j in range(width):\n",
    "            new_img[i+mask_size].append(img[i][j])\n",
    "        # middle right\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+mask_size].append(img[i][j])\n",
    "    for i in range(mask_size):\n",
    "        new_img.append([])\n",
    "        # bottom left corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+length+mask_size].append(img[i][width-mask_size+j])\n",
    "        # bottom center\n",
    "        for j in range(width):\n",
    "            new_img[i+length+mask_size].append(img[i][j])\n",
    "        # bottom right corner\n",
    "        for j in range(mask_size):\n",
    "            new_img[i+length+mask_size].append(img[i][j])\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_3x3 = [[1, 2, 1], [2, 4, 2], [1, 2, 1]]\n",
    "gauss_5x5 = [[1, 4, 7, 4, 1], [4, 16, 26, 16, 4], [7, 26, 41, 26, 7],\n",
    "            [4, 16, 26, 16, 4], [1, 4, 7, 4, 1]]\n",
    "dilate_erode_weights = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_linear_filter(img, weights=gauss_5x5, sum_weights=0):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    ext_img = ext_bounds(img, length, width, mask_radius)\n",
    "\n",
    "    # sum_weights can be changed from 0 for an edge detector or other\n",
    "    # filter where the sum would equal 0 and cause zero division error.\n",
    "    # Otherwise, the function will figure it out, below.\n",
    "    if sum_weights == 0:\n",
    "        for i in range(len(weights)):\n",
    "            sum_weights += sum(weights[i])\n",
    "        \n",
    "        if sum_weights == 0:\n",
    "            print(\"please supply a non-zero sum_weights for this filter,\\\n",
    "            maybe the sum of their absolute values.\")\n",
    "    \n",
    "    # apply filter\n",
    "    new_img = []\n",
    "    for i in range(mask_radius, length + mask_radius):\n",
    "        new_img.append([])\n",
    "        for j in range(mask_radius, width + mask_radius):\n",
    "            summed = 0\n",
    "            for k in range(len(weights)):\n",
    "                for m in range(len(weights[k])):\n",
    "                    summed += ext_img[i-mask_radius+k][j-mask_radius+m] *\\\n",
    "                    weights[k][m]\n",
    "            new_img[i-mask_radius].append(summed / sum_weights)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_linear_filter(img, weights=gauss_5x5):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    ext_img = ext_bounds(img, length, width, mask_radius)\n",
    "\n",
    "    # apply filter\n",
    "    new_img = []\n",
    "    for i in range(mask_radius, length + mask_radius):\n",
    "        new_img.append([])\n",
    "        for j in range(mask_radius, width + mask_radius):\n",
    "            products = []\n",
    "            for k in range(len(weights)):\n",
    "                for m in range(len(weights[k])):\n",
    "                    for _ in range(weights[k][m]):\n",
    "                        products.append(ext_img[i-mask_radius+k][j-mask_radius+m])\n",
    "            new_img[i-mask_radius].append(st.median(products))\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(folder, funcs, abbr=None, save_loc=None, verbose=False):\n",
    "    # funcs should be a tuple or list like:\n",
    "    # [[func1, {param1:arg1, param2:arg2}], [func2, {param1:arg1}]]\n",
    "    # where paramaters are anything besides \"img\" or \"folder\"\n",
    "    \n",
    "    # abbr can be:\n",
    "    # \"cyl\": columnar epithelial?\n",
    "    # \"para\": parabasal squamous epithelial\n",
    "    # \"inter\": intermediate squamous epithelial\n",
    "    # \"super\": superficial squamous epithelial\n",
    "    # \"let\": mild nonkeratinizing dysplastic?\n",
    "    # \"mod\": moderate nonkeratinizing dysplastic\n",
    "    # \"svar\": severe nonkeratinizing dysplastic?\n",
    "    # if we only want to apply provided functions to one type of cell\n",
    "    if abbr:\n",
    "        files = glob.glob(f\"{folder}/{abbr}*\")\n",
    "    else:\n",
    "        files = glob.glob(f\"{folder}/*\")\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    num = 0\n",
    "    sum_msqe = 0\n",
    "    bin_list = []\n",
    "    count_list = []\n",
    "    # open and grayscale each file\n",
    "    for file in files:\n",
    "        num += 1\n",
    "        pix_list = open_in_gray(file)\n",
    "        for func in funcs:\n",
    "            if func[0] == quantizer:\n",
    "                pix_list, msqe = func[0](pix_list, **(func[1]))\n",
    "                sum_msqe += msqe\n",
    "            elif func[0] == hist:\n",
    "                bins, counts = func[0](pix_list, **(func[1]))\n",
    "                bin_list.append(bins)\n",
    "                count_list.append(counts)\n",
    "            else:\n",
    "                pix_list = func[0](pix_list, **(func[1]))\n",
    "        if save_loc:\n",
    "            to_image(pix_list, save_loc=f\"{save_loc}/out{num}.png\")\n",
    "        else:\n",
    "            to_image(pix_list)\n",
    "\n",
    "    if verbose:\n",
    "        # statistics\n",
    "        end = time.perf_counter()\n",
    "        batch = end - start\n",
    "        ind = batch / len(files)\n",
    "        out_string = f\"batch time: {batch}\\naverage individual time: {ind}\"\n",
    "        if quantizer in [func[0] for func in funcs]:\n",
    "            out_string += f\"\\n mean of msqe: {sum_msqe/len(files)}\"\n",
    "    \n",
    "        print(out_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge operator function, can do Prewitt, Sobel, or Jahne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_operator(img, type=\"Jahne\", sharpen_thresh=0):\n",
    "    new_img_x = []\n",
    "    new_img_y = []\n",
    "    if type == \"Prewitt\":\n",
    "        x_mask = [[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]\n",
    "        y_mask = [[-1, -1, -1], [0, 0, 0], [1, 1, 1]]\n",
    "        new_img_x = avg_linear_filter(img, weights=x_mask, sum_weights=6)\n",
    "        new_img_y = avg_linear_filter(img, weights=y_mask, sum_weights=6)\n",
    "    elif type == \"Sobel\":\n",
    "        x_mask = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "        y_mask = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
    "        new_img_x = avg_linear_filter(img, weights=x_mask, sum_weights=8)\n",
    "        new_img_y = avg_linear_filter(img, weights=y_mask, sum_weights=8)\n",
    "    elif type == \"Jahne\":\n",
    "        x_mask = [[-3, 0, 3], [-10, 0, 10], [-3, 0, 3]]\n",
    "        y_mask = [[-3, -10, -3], [0, 0, 0], [3, 10, 3]]\n",
    "        new_img_x = avg_linear_filter(img, weights=x_mask, sum_weights=32)\n",
    "        new_img_y = avg_linear_filter(img, weights=y_mask, sum_weights=32)\n",
    "\n",
    "    length = len(new_img_y)\n",
    "    width = len(new_img_y[0])\n",
    "    new_img = []\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            grad = math.sqrt(new_img_x[i][j]**2 + new_img_y[i][j]**2)\n",
    "            if sharpen_thresh > 0:\n",
    "                if grad > sharpen_thresh:\n",
    "                    new_img[i].append(255)\n",
    "                else:\n",
    "                    new_img[i].append(0)\n",
    "            else:\n",
    "                new_img[i].append(grad)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram thresholding â€“ single threshold that divides image into two segments: foreground (cells) and background (everything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_thresh(img):\n",
    "    bins, counts = hist(img)\n",
    "    num_pix = sum(counts)\n",
    "    within_group_vars = []\n",
    "\n",
    "    for thresh in range(2, 255):\n",
    "        obj_prior = sum(counts[:thresh]) / num_pix\n",
    "        back_prior = sum(counts[thresh:]) / num_pix\n",
    "\n",
    "        if obj_prior != 0:\n",
    "            obj_mean = (sum([i * counts[i] for i in range(thresh)]) / num_pix)\\\n",
    "                / obj_prior\n",
    "            obj_var = sum([(i - obj_mean)**2 * counts[i] for i in range(thresh)])\\\n",
    "                / (num_pix * obj_prior)\n",
    "        else:\n",
    "            obj_var = 0\n",
    "        \n",
    "        if back_prior != 0:\n",
    "            back_mean = (sum([i * counts[i] for i in range(thresh, 255)]) / num_pix)\\\n",
    "                / back_prior\n",
    "            back_var = sum([(i - back_mean)**2 * counts[i] for i in range(thresh, 255)])\\\n",
    "                / (num_pix * back_prior)\n",
    "        else:\n",
    "            back_var = 0\n",
    "\n",
    "        within_group_vars.append(obj_var * obj_prior + back_var * back_prior)\n",
    "    \n",
    "    index = within_group_vars.index(min(within_group_vars))\n",
    "    threshold = bins[index+1]\n",
    "\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "\n",
    "    new_img = []\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            if img[i][j] <= threshold:\n",
    "                new_img[i].append(0)\n",
    "            else:\n",
    "                new_img[i].append(255)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dilation and erosion operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(img, weights):\n",
    "    # use a square filter with 0 for negative (white) and 1 for positive (black)\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    binary = hist_thresh(img)\n",
    "    new_img = []\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            new_img[i].append(255)\n",
    "\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            if binary[i][j] == 0:\n",
    "                for m in range(-mask_radius, mask_radius + 1):\n",
    "                    for n in range(-mask_radius, mask_radius + 1):\n",
    "                        if weights[m+mask_radius][n+mask_radius] == 1\\\n",
    "                            and i + m >= 0 and i + m < length\\\n",
    "                            and j + n > 0 and j + n < width:\n",
    "                            new_img[i+m][j+n] = 0\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode(img, weights):\n",
    "    # use a square filter with 0 for negative (white) and 1 for positive (black)\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    mask_radius = math.floor(len(weights) / 2)\n",
    "    binary = hist_thresh(img)\n",
    "    new_img = []\n",
    "\n",
    "    for i in range(length):\n",
    "        new_img.append([])\n",
    "        for j in range(width):\n",
    "            new_img[i].append(255)\n",
    "\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            present = True\n",
    "            for m in range(-mask_radius, mask_radius + 1):\n",
    "                for n in range(-mask_radius, mask_radius + 1):\n",
    "                    if weights[m+mask_radius][n+mask_radius] == 1\\\n",
    "                        and i + m >= 0 and i + m < length\\\n",
    "                        and j + n > 0 and j + n < width:\n",
    "                        if binary[i+m][j+n] != 0:\n",
    "                            present = False\n",
    "                            break\n",
    "                if not present:\n",
    "                    break\n",
    "            if present:    \n",
    "                new_img[i][j] = 0\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_quantize(img, k, iter=10):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "\n",
    "    intensity = random.sample(range(256), k)\n",
    "    centroids = [i for i in intensity]\n",
    "\n",
    "    new_img = [[0 for _ in range(width)] for _ in range(length)]\n",
    "\n",
    "    for _ in range(iter):\n",
    "        # sums keeps track of the sum for [x, y, intensity] for each centroid\n",
    "        # counts is number of points assigned to each centroid\n",
    "        sums = [0 for _ in range(k)]\n",
    "        counts = [0 for _ in range(k)]\n",
    "\n",
    "        for i in range(length):\n",
    "            for j in range(width):\n",
    "                cent_dist = 9999999999999\n",
    "                closest = 0\n",
    "\n",
    "                for m in range(k):\n",
    "                    int_dist = centroids[m] - img[i][j]\n",
    "                    dist = math.sqrt(int_dist**2)\n",
    "\n",
    "                    if dist < cent_dist:\n",
    "                        cent_dist = dist\n",
    "                        closest = m\n",
    "                \n",
    "                # assign pixels to centroids and update stats for cluster centroids\n",
    "                new_img[i][j] = closest\n",
    "                sums[closest] += img[i][j]\n",
    "                counts[closest] += 1\n",
    "            \n",
    "        # move centroids to avg of assigned pixels\n",
    "        for m in range(k):\n",
    "            if counts[m] != 0:\n",
    "                centroids[m] = sums[m] / counts[m]\n",
    "\n",
    "    colors = list(range(0, 256, math.floor(255/(k - 1))))\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            new_img[i][j] = colors[new_img[i][j]]\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_dist(img, k, iter=10, dist_weight=.25):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    avg_dim = (width + length) / 2\n",
    "\n",
    "    ii = random.sample(range(length), k)\n",
    "    jj = random.sample(range(width), k)\n",
    "    intensity = random.sample(range(256), k)\n",
    "    centroids = [[i, j, inten] for i, j, inten in zip(ii, jj, intensity)]\n",
    "\n",
    "    new_img = [[0 for _ in range(width)] for _ in range(length)]\n",
    "\n",
    "    for _ in range(iter):\n",
    "        # sums keeps track of the sum for [x, y, intensity] for each centroid\n",
    "        # counts is number of points assigned to each centroid\n",
    "        sums = [[0, 0, 0] for _ in range(k)]\n",
    "        counts = [0 for _ in range(k)]\n",
    "\n",
    "        for i in range(length):\n",
    "            for j in range(width):\n",
    "                cent_dist = 9999999999999\n",
    "                closest = 0\n",
    "\n",
    "                for m in range(k):\n",
    "                    i_dist = centroids[m][0] - i\n",
    "                    j_dist = centroids[m][1] - j\n",
    "                    int_dist = centroids[m][2] - img[i][j]\n",
    "\n",
    "                    # intensity is scaled by the avg of the dimensions, distances can be\n",
    "                    # scaled by dist_weight\n",
    "                    dist = math.sqrt((i_dist * dist_weight)**2 + (j_dist * dist_weight)**2\\\n",
    "                        + (int_dist * avg_dim / 255)**2)\n",
    "\n",
    "                    if dist < cent_dist:\n",
    "                        cent_dist = dist\n",
    "                        closest = m\n",
    "                \n",
    "                # assign pixels to centroids and update stats for cluster centroids\n",
    "                new_img[i][j] = closest\n",
    "                sums[closest][0] += i\n",
    "                sums[closest][1] += j\n",
    "                sums[closest][2] += img[i][j]\n",
    "                counts[closest] += 1\n",
    "            \n",
    "        # move centroids to avg of assigned pixels\n",
    "        for m in range(k):\n",
    "            if counts[m] != 0:\n",
    "                centroids[m][0] = sums[m][0] / counts[m]\n",
    "                centroids[m][1] = sums[m][1] / counts[m]\n",
    "                centroids[m][2] = sums[m][2] / counts[m]\n",
    "\n",
    "    colors = list(range(0, 256, math.floor(255/(k - 1))))\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            new_img[i][j] = colors[new_img[i][j]]\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(img, radius=10, min_obj=60):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    avg_dim = (length + width) / 2\n",
    "\n",
    "    new_img = [[0 for _ in range(width)] for _ in range(length)]\n",
    "\n",
    "    cores = []\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            n_nearby = 0\n",
    "            nearby = []\n",
    "            # searching within a circle within a square - there's probably a better way to do this\n",
    "            for m in range(-radius, radius):\n",
    "                for n in range(-radius, radius):\n",
    "                    if i + m >= 0 and j + n >= 0 and i + m < length and j + n < width:\n",
    "                        # scale the intensity distance to image dimensions\n",
    "                        int_dist = (img[i][j] - img[i+m][j+n]) * avg_dim / 255\n",
    "                        if math.sqrt(m**2 + n**2 + int_dist**2) <= radius:\n",
    "                            n_nearby += 1\n",
    "                            nearby.append([i + m, j + n])\n",
    "                            new_img[i+m][j+n] = -1\n",
    "\n",
    "            if n_nearby >= min_obj:\n",
    "                cores.append({\"loc\": [i, j], \"neighbors\": nearby})\n",
    "                new_img[i][j] = -1\n",
    "\n",
    "    clusters = {}\n",
    "    cluster_serial = 0\n",
    "    for core in cores:\n",
    "        # 0 for the pixel value will stand in for \"background\", 1, 2, 3, etc. will be cluster #s\n",
    "        # if we find a background core, make it the start of a new cluster\n",
    "        i = core[\"loc\"][0]\n",
    "        j = core[\"loc\"][1]\n",
    "        if new_img[i][j] == -1:\n",
    "            new_img[i][j] = cluster_serial\n",
    "            clusters[str(cluster_serial)] = [[i, j]]\n",
    "            cluster_serial += 1\n",
    "        # go through the neighbors of the core and add them to the core's cluster if they are background\n",
    "        for point in core[\"neighbors\"]:\n",
    "            m = point[0]\n",
    "            n = point[1]\n",
    "            if new_img[m][n] == -1:\n",
    "                new_img[m][n] = new_img[i][j]\n",
    "                clusters[str(new_img[i][j])].append([m, n])\n",
    "\n",
    "            # if we find a point belonging to a different cluster, add this cluster to that one\n",
    "            elif new_img[m][n] != new_img[i][j]:\n",
    "                temp = str(new_img[i][j])\n",
    "                for nb in clusters[str(new_img[i][j])]:\n",
    "                    new_img[nb[0]][nb[1]] = new_img[m][n]\n",
    "\n",
    "                clusters[str(new_img[m][n])].extend(clusters[temp])\n",
    "                clusters.pop(temp)\n",
    "    if cluster_serial > 0:\n",
    "        step = 255/len(clusters)\n",
    "        colors = list(arange(step, 255 + step, step))\n",
    "        cluster_keys = list(clusters.keys())\n",
    "        for i in range(length):\n",
    "            for j in range(width):\n",
    "                if new_img[i][j] == -1:\n",
    "                    new_img[i][j] = 0\n",
    "                else:\n",
    "                    cluster_index = cluster_keys.index(str(new_img[i][j]))\n",
    "                    new_img[i][j] = colors[cluster_index]\n",
    "\n",
    "    return new_img, len(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_perimeter takes a binary segmented image with objects in black and background in white and returns the length of the outer boundaries of all objects within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_seg(img, radius=10, min_obj=60):\n",
    "    length = len(img)\n",
    "    width = len(img[0])\n",
    "    avg_dim = (length + width) / 2\n",
    "\n",
    "    new_img = [[0 for _ in range(width)] for _ in range(length)]\n",
    "\n",
    "    cores = []\n",
    "    for i in range(length):\n",
    "        for j in range(width):\n",
    "            n_nearby = 0\n",
    "            nearby = []\n",
    "            # searching within a circle within a square - there's probably a better way to do this\n",
    "            for m in range(-radius, radius):\n",
    "                for n in range(-radius, radius):\n",
    "                    if i + m >= 0 and j + n >= 0 and i + m < length and j + n < width:\n",
    "                        # scale the intensity distance to image dimensions\n",
    "                        int_dist = (img[i][j] - img[i+m][j+n]) * avg_dim / 255\n",
    "                        if math.sqrt(m**2 + n**2 + int_dist**2) <= radius:\n",
    "                            n_nearby += 1\n",
    "                            nearby.append([i + m, j + n])\n",
    "                            new_img[i+m][j+n] = -1\n",
    "\n",
    "            if n_nearby >= min_obj:\n",
    "                cores.append({\"loc\": [i, j], \"neighbors\": nearby})\n",
    "                new_img[i][j] = -1\n",
    "\n",
    "    clusters = {}\n",
    "    cluster_serial = 0\n",
    "    for core in cores:\n",
    "        # 0 for the pixel value will stand in for \"background\", 1, 2, 3, etc. will be cluster #s\n",
    "        # if we find a background core, make it the start of a new cluster\n",
    "        i = core[\"loc\"][0]\n",
    "        j = core[\"loc\"][1]\n",
    "        if new_img[i][j] == -1:\n",
    "            new_img[i][j] = cluster_serial\n",
    "            clusters[str(cluster_serial)] = [[i, j]]\n",
    "            cluster_serial += 1\n",
    "        # go through the neighbors of the core and add them to the core's cluster if they are background\n",
    "        for point in core[\"neighbors\"]:\n",
    "            m = point[0]\n",
    "            n = point[1]\n",
    "            if new_img[m][n] == -1:\n",
    "                new_img[m][n] = new_img[i][j]\n",
    "                clusters[str(new_img[i][j])].append([m, n])\n",
    "\n",
    "            # if we find a point belonging to a different cluster, add this cluster to that one\n",
    "            elif new_img[m][n] != new_img[i][j]:\n",
    "                temp = str(new_img[i][j])\n",
    "                for nb in clusters[str(new_img[i][j])]:\n",
    "                    new_img[nb[0]][nb[1]] = new_img[m][n]\n",
    "\n",
    "                clusters[str(new_img[m][n])].extend(clusters[temp])\n",
    "                clusters.pop(temp)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perimeter(seg_img):\n",
    "    cross_weights = [[0, 1, 0], [1, 1, 1], [0, 1, 0]]\n",
    "    dilated = dilate(seg_img, weights=cross_weights)\n",
    "    dilated_1d = ravel(dilated) + 255\n",
    "    seg_1d = ravel(seg)\n",
    "    outlines = dilated_1d - seg_1d\n",
    "    negative = outlines - 255\n",
    "    return -sum(negative) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_area_bbox_com(clusters):\n",
    "    areas = []\n",
    "    bboxs = []\n",
    "    coms = []\n",
    "    for cluster_k in clusters.keys():\n",
    "        num_points = len(clusters[cluster_k])\n",
    "        areas.append(num_points)\n",
    "\n",
    "        j_sum = k_sum = j_max = k_max = 0\n",
    "        j_min = k_min = 100000\n",
    "        for i in range(num_points):\n",
    "            j = clusters[cluster_k][i][0]\n",
    "            k = clusters[cluster_k][i][1]\n",
    "            j_sum += j\n",
    "            k_sum += k\n",
    "            if j < j_min:\n",
    "                j_min = j\n",
    "            if k < k_min:\n",
    "                k_min = k\n",
    "            if j > j_max:\n",
    "                j_max = j\n",
    "            if k > k_max:\n",
    "                k_max = k\n",
    "\n",
    "        bbox_top_left = [j_min, k_min]\n",
    "        bbox_bottom_right = [j_max, k_max]\n",
    "        center_of_mass = [round(j_sum / num_points), round(k_sum / num_points)]\n",
    "\n",
    "        bboxs.append([bbox_top_left, bbox_bottom_right])\n",
    "        coms.append(center_of_mass)\n",
    "    \n",
    "    return areas, bboxs, coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxs(img, bboxs):\n",
    "    img_draw = copy.deepcopy(img)\n",
    "    for i in range(len(bboxs)):\n",
    "        br_y = bboxs[i][1][0]\n",
    "        tl_y = bboxs[i][0][0]\n",
    "        br_x = bboxs[i][1][1]\n",
    "        tl_x = bboxs[i][0][1]\n",
    "        for j in range(br_y - tl_y):\n",
    "            img_draw[tl_y+j][tl_x] = 125\n",
    "            img_draw[tl_y+j][br_x] = 125\n",
    "        for k in range(br_x - tl_x):\n",
    "            img_draw[tl_y][tl_x+k] = 125\n",
    "            img_draw[br_y][tl_x+k] = 125\n",
    "\n",
    "    img_1d = ravel(img_draw)\n",
    "    output = Image.new(\"L\", [len(img[0]), len(img)])\n",
    "    output.putdata(img_1d)\n",
    "    output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_in_gray(\"Cancerous cell smears/cyl01.BMP\")\n",
    "# get rid of annoying line artifacts on the edges\n",
    "crop_img = [x[3:-3] for x in img[3:-3]]\n",
    "seg = k_means_quantize(crop_img, 2)\n",
    "# just to clean it up a bit\n",
    "clean = dilate(erode(seg, weights=dilate_erode_weights), weights=dilate_erode_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=762x562>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = len(clean[0])\n",
    "length = len(clean)\n",
    "\n",
    "clustered, num_clusters = dbscan(clean)\n",
    "clustered_1d = ravel(clustered)\n",
    "output = Image.new(\"L\", [width, length])\n",
    "output.putdata(clustered_1d)\n",
    "print(num_clusters)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats(img):\n",
    "    # features extracted:\n",
    "    # center of mass and central moments\n",
    "    # orientation\n",
    "\n",
    "    # get rid of annoying line artifacts on the edges\n",
    "    crop_img = [x[3:-3] for x in img[3:-3]]\n",
    "    # binarize image\n",
    "    seg = k_means_quantize(img, 2)\n",
    "    dilate_erode_weights = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]\n",
    "    # clean it up a bit\n",
    "    clean = erode(dilate(seg, weights=dilate_erode_weights), weights=dilate_erode_weights)\n",
    "\n",
    "    # get object clusters (pixel locations) from image\n",
    "    clusters = dbscan_seg(clean)\n",
    "    # get the background cluster out of there\n",
    "    avg_intensities = []\n",
    "    keys = []\n",
    "    for cluster_k in clusters.keys():\n",
    "        num_points = len(clusters[cluster_k])\n",
    "        sum_intensity = 0\n",
    "        for i in range(num_points):\n",
    "            j = clusters[cluster_k][i][0]\n",
    "            k = clusters[cluster_k][i][1]\n",
    "            sum_intensity += clean[j][k]\n",
    "        avg_intensities.append(sum_intensity / num_points)\n",
    "        keys.append((cluster_k))\n",
    "\n",
    "    max_index = avg_intensities.index(max(avg_intensities))\n",
    "    clusters.pop(keys[max_index])\n",
    "\n",
    "    areas, bboxs, coms = get_area_bbox_com(clusters)\n",
    "\n",
    "    height = len(img)\n",
    "    width = len(img[0])\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if img[i][j] > 0:\n",
    "                pix_sum += 1 "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cf590adf64b12f100e2631293f66eedf21812d31d21d345d3dafaac5b13c0f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
